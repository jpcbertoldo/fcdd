{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# train mvtec\n",
    "\n",
    "i want to have a simpler script to integrate to wandb and later adapt it to unetdd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# consts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "from typing import List\n",
    "from fcdd.datasets.bases import TorchvisionDataset\n",
    "from fcdd.datasets.cifar import ADCIFAR10\n",
    "from fcdd.datasets.fmnist import ADFMNIST\n",
    "from fcdd.datasets.imagenet import ADImageNet\n",
    "from fcdd.datasets.mvtec import ADMvTec\n",
    "from fcdd.datasets.pascal_voc import ADPascalVoc\n",
    "from fcdd.datasets.image_folder import ADImageFolderDataset\n",
    "from fcdd.datasets.image_folder_gtms import ADImageFolderDatasetGTM\n",
    "\n",
    "DS_CHOICES = ('mnist', 'cifar10', 'fmnist', 'mvtec', 'imagenet', 'pascalvoc')\n",
    "PREPROC_CHOICES = (\n",
    "    'lcn', 'lcnaug1', 'aug1', 'aug1_blackcenter', 'aug1_blackcenter_inverted', 'none'\n",
    ")\n",
    "SUPERVISE_MODES = ('unsupervised', 'other', 'noise', 'malformed_normal', 'malformed_normal_gt')\n",
    "NOISE_MODES = [\n",
    "    'gaussian', 'uniform', 'blob', 'mixed_blob', 'solid', 'confetti',  # Synthetic Anomalies\n",
    "    'imagenet', 'imagenet22k', 'cifar100', 'emnist',  # Outlier Exposure\n",
    "    'mvtec', 'mvtec_gt'  # Outlier Exposure online supervision only\n",
    "]\n",
    "\n",
    "def str_labels(dataset_name: str) -> List[str]:\n",
    "    return {\n",
    "        'cifar10': [\n",
    "            'airplane', 'automobile', 'bird', 'cat', 'deer', \n",
    "            'dog', 'frog', 'horse', 'ship', 'truck'\n",
    "        ],\n",
    "        'fmnist': [\n",
    "            't-shirt/top', 'trouser', 'pullover', 'dress', 'coat', \n",
    "            'sandal', 'shirt', 'sneaker', 'bag', 'ankle boot'\n",
    "        ],\n",
    "        'mvtec': [\n",
    "            'bottle', 'cable', 'capsule', 'carpet', 'grid', 'hazelnut', 'leather',\n",
    "            'metal_nut', 'pill', 'screw', 'tile', 'toothbrush', 'transistor',\n",
    "            'wood', 'zipper'\n",
    "        ],\n",
    "        'imagenet': deepcopy(ADImageNet.ad_classes),\n",
    "        'pascalvoc': ['horse'],\n",
    "    }[dataset_name]\n",
    "\n",
    "\n",
    "def no_classes(dataset_name: str) -> int:\n",
    "    return len(str_labels[dataset_name])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path as pt\n",
    "from argparse import ArgumentParser\n",
    "\n",
    "import numpy as np\n",
    "from fcdd.models import choices\n",
    "\n",
    "\n",
    "def default_parser_config(parser: ArgumentParser) -> ArgumentParser:\n",
    "    \"\"\"\n",
    "    Defines all the arguments for running an FCDD experiment.\n",
    "    :param parser: instance of an ArgumentParser.\n",
    "    :return: the parser with added arguments\n",
    "    \"\"\"\n",
    "\n",
    "    # define directories for datasets and logging\n",
    "    parser.add_argument(\n",
    "        '--logdir', type=str, default=pt.join('..', '..', 'data', 'results', 'fcdd_{t}'),\n",
    "        help='Directory where log data is to be stored. The pattern {t} is replaced by the start time. '\n",
    "             'Defaults to ../../data/results/fcdd_{t}. '\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        '--logdir-suffix', type=str, default='',\n",
    "        help='String suffix for log directory, again {t} is replaced by the start time. '\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        '--datadir', type=str, default=pt.join('..', '..', 'data', 'datasets'),\n",
    "        help='Directory where datasets are found or to be downloaded to. Defaults to ../../data/datasets.',\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        '--readme', type=str, default='',\n",
    "        help='Some notes to be stored in the automatically created config.txt configuration file.'\n",
    "    )\n",
    "\n",
    "    # training parameters\n",
    "    parser.add_argument('-b', '--batch-size', type=int, default=128)\n",
    "    parser.add_argument('-e', '--epochs', type=int, default=200)\n",
    "    parser.add_argument('-w', '--workers', type=int, default=4)\n",
    "    parser.add_argument('-lr', '--learning_rate', type=float, default=1e-3)\n",
    "    parser.add_argument('-wd', '--weight-decay', type=float, default=1e-6)\n",
    "    parser.add_argument(\n",
    "        '--optimizer-type', type=str, default='sgd', choices=['sgd', 'adam'],\n",
    "        help='The type of optimizer. Defaults to \"sgd\". '\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        '--scheduler-type', type=str, default='lambda', choices=['lambda', 'milestones'],\n",
    "        help='The type of learning rate scheduler. Either \"lambda\", which reduces the learning rate each epoch '\n",
    "             'by a certain factor, or \"milestones\", which sets the learning rate to certain values at certain '\n",
    "             'epochs. Defaults to \"lambda\"'\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        '--lr-sched-param', type=float, nargs='*', default=[0.985],\n",
    "        help='Sequence of learning rate scheduler parameters. '\n",
    "             'For the \"lambda\" scheduler, just one parameter is allowed, '\n",
    "             'which sets the factor the learning rate is reduced per epoch. '\n",
    "             'For the \"milestones\" scheduler, at least two parameters are needed, '\n",
    "             'the first determining the factor by which the learning rate is reduced at each milestone, '\n",
    "             'and the others being each a milestone. For instance, \"0.1 100 200 300\" reduces the learning rate '\n",
    "             'by 0.1 at epoch 100, 200, and 300. '\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        '--load', type=str, default=None,\n",
    "        help='Path to a file that contains a snapshot of the network model. '\n",
    "             'When given, the network loads the found weights and state of the training. '\n",
    "             'If epochs are left to be trained, the training is continued. '\n",
    "             'Note that only one snapshot is given, thus using a runner that trains for multiple different classes '\n",
    "             'to be nominal is not applicable. '\n",
    "    )\n",
    "    parser.add_argument('-d', '--dataset', type=str, default='custom', choices=DS_CHOICES)\n",
    "    parser.add_argument(\n",
    "        '-n', '--net', type=str, default='FCDD_CNN224_VGG_F', choices=choices(),\n",
    "        help='Chooses a network architecture to train.'\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        '--preproc', type=str, default='aug1', choices=PREPROC_CHOICES,\n",
    "        help='Determines the kind of preprocessing pipeline (augmentations and such). '\n",
    "             'Have a look at the code (dataset implementation, e.g. fcdd.datasets.cifar.py) for details.'\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        '--acc-batches', type=int, default=1,\n",
    "        help='To speed up data loading, '\n",
    "             'this determines the number of batches that are accumulated to be used for training. '\n",
    "             'For instance, acc_batches=2 iterates the data loader two times, concatenates the batches, and '\n",
    "             'passes the result to the further training procedure. This has no impact on the performance '\n",
    "             'if the batch size is reduced accordingly (e.g. one half in this example), '\n",
    "             'but can decrease training time. '\n",
    "    )\n",
    "    parser.add_argument('--no-bias', dest='bias', action='store_false', help='Uses no bias in network layers.')\n",
    "    parser.add_argument('--cpu', dest='cuda', action='store_false', help='Trains on CPU only.')\n",
    "\n",
    "    # artificial anomaly settings\n",
    "    parser.add_argument(\n",
    "        '--supervise-mode', type=str, default='noise', choices=SUPERVISE_MODES,\n",
    "        help='This determines the kind of artificial anomalies. '\n",
    "             '\"unsupervised\" uses no anomalies at all. '\n",
    "             '\"other\" uses ground-truth anomalies. '\n",
    "             '\"noise\" uses pure noise images or Outlier Exposure. '\n",
    "             '\"malformed_normal\" adds noise to nominal images to create malformed nominal anomalies. '\n",
    "             '\"malformed_normal_gt\" is like malformed_normal, but with ground-truth anomaly heatmaps for training. '\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        '--noise-mode', type=str, default='imagenet22k', choices=NOISE_MODES,\n",
    "        help='The type of noise used when artificial anomalies are activated. Dataset names refer to OE. '\n",
    "             'See fcdd.datasets.noise_modes.py.'\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        '--oe-limit', type=int, default=np.infty,\n",
    "        help='Determines the amount of different samples used for Outlier Exposure. '\n",
    "             'Has no impact on synthetic anomalies.'\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        '--offline-supervision', dest='online_supervision', action='store_false',\n",
    "        help='Instead of sampling artificial anomalies during training by having a 50%% chance to '\n",
    "             'replace nominal samples, this mode samples them once at the start of the training and adds them to '\n",
    "             'the training set. '\n",
    "             'This yields less performance and higher RAM utilization, but reduces the training time. '\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        '--nominal-label', type=int, default=0,\n",
    "        help='Determines the label that marks nominal samples. '\n",
    "             'Note that this is not the class that is considered nominal! '\n",
    "             'For instance, class 5 is the nominal class, which is labeled with the nominal label 0.'\n",
    "    )\n",
    "\n",
    "    # heatmap generation parameters\n",
    "    parser.add_argument(\n",
    "        '--blur-heatmaps', dest='blur_heatmaps', action='store_true',\n",
    "        help='Blurs heatmaps, like done for the explanation baseline experiments in the paper.'\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        '--gauss-std', type=float, default=10,\n",
    "        help='Sets a constant value for the standard deviation of the Gaussian kernel used for upsampling and '\n",
    "             'blurring.'\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        '--quantile', type=float, default=0.97,\n",
    "        help='The quantile that is used to normalize the generated heatmap images. '\n",
    "             'This is explained in the Appendix of the paper.'\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        '--resdown', type=int, default=64,\n",
    "        help='Sets the maximum resolution of logged images (per heatmap), images will be downsampled '\n",
    "             'if they exceed this threshold. For instance, resdown=64 makes every image of heatmaps contain '\n",
    "             'individual heatmaps and inputs of width 64 and height 64 at most.'\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        '--no-test', dest=\"test\", action=\"store_false\",\n",
    "        help='If set then the model will not be tested at the end of the training. It will by default.'\n",
    "    )\n",
    "    return parser\n",
    "\n",
    "\n",
    "def default_parser_config_mvtec(parser: ArgumentParser) -> ArgumentParser:\n",
    "    parser = default_parser_config(parser)\n",
    "    parser.set_defaults(\n",
    "        batch_size=16, \n",
    "        acc_batches=8, \n",
    "        supervise_mode='malformed_normal',\n",
    "        gauss_std=12, \n",
    "        weight_decay=1e-4, \n",
    "        epochs=200, \n",
    "        preproc='lcnaug1',\n",
    "        quantile=0.99, \n",
    "        net='FCDD_CNN224_VGG_F', \n",
    "        dataset='mvtec', \n",
    "        noise_mode='confetti',\n",
    "    )\n",
    "\n",
    "    parser.add_argument(\n",
    "        '--it', type=int, default=5, \n",
    "        help='Number of runs per class with different random seeds.')\n",
    "    parser.add_argument(\n",
    "        '--cls-restrictions', type=int, nargs='+', default=None,\n",
    "        help='Run only training sessions for some of the classes being nominal.'\n",
    "    )\n",
    "    return parser\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = ArgumentParser(\n",
    "    description=\"\"\"\n",
    "    Train a neural network module as explained in the `Explainable Deep Anomaly Detection` paper.\n",
    "    Train FCDD, and log achieved scores, metrics, plots, and heatmaps\n",
    "    for both test and training data. \n",
    "    \"\"\"\n",
    ")\n",
    "parser = default_parser_config_mvtec(parser)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "def time_format(i: float) -> str:\n",
    "    \"\"\" takes a timestamp (seconds since epoch) and transforms that into a datetime string representation \"\"\"\n",
    "    return datetime.fromtimestamp(i).strftime('%Y%m%d%H%M%S')\n",
    "\n",
    "\n",
    "def args_post_parse(args_):\n",
    "    \n",
    "    args_.logdir = Path(args_.logdir)\n",
    "    logdir_name = args_.logdir.name\n",
    "    \n",
    "    # it is duplicated for compatibility with setup_trainer\n",
    "    args_.log_start_time = int(time.time())\n",
    "    args_.log_start_time_str = time_format(args_.log_start_time)\n",
    "    \n",
    "    logdir_name = f\"{args_.dataset}_\" + logdir_name\n",
    "    \n",
    "    if 'logdir_suffix' in vars(args_):\n",
    "        logdir_name += args_.logdir_suffix\n",
    "        del vars(args_)['logdir_suffix']\n",
    "        \n",
    "    logdir_name = logdir_name.replace('{t}', args_.log_start_time_str)\n",
    "    \n",
    "    args_.logdir = args_.logdir.parent / logdir_name\n",
    "            \n",
    "    return args_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import namedtuple\n",
    "\n",
    "TrainSetup = namedtuple(\n",
    "    \"TrainSetup\",\n",
    "    [\n",
    "        \"net\",\n",
    "        \"dataset_loaders\",\n",
    "        \"opt\",\n",
    "        \"sched\",\n",
    "        \"logger\",\n",
    "        \"device\",\n",
    "        \"quantile\",\n",
    "        \"resdown\",\n",
    "        \"gauss_std\",\n",
    "        \"blur_heatmaps\",\n",
    "    ]\n",
    ")\n",
    "\n",
    "def trainer_setup(\n",
    "    dataset: str, \n",
    "    datadir: str, \n",
    "    logdir: str, \n",
    "    net: str, \n",
    "    bias: bool,\n",
    "    learning_rate: float, \n",
    "    weight_decay: float, \n",
    "    lr_sched_param: List[float], \n",
    "    batch_size: int,\n",
    "    optimizer_type: str, \n",
    "    scheduler_type: str,\n",
    "    preproc: str, \n",
    "    supervise_mode: str, \n",
    "    nominal_label: int,\n",
    "    online_supervision: bool, \n",
    "    oe_limit: int, \n",
    "    noise_mode: str,\n",
    "    workers: int, \n",
    "    quantile: float, \n",
    "    resdown: int, \n",
    "    gauss_std: float, \n",
    "    blur_heatmaps: bool,\n",
    "    cuda: bool, \n",
    "    config: str, \n",
    "    log_start_time: int = None, \n",
    "    normal_class: int = 0,\n",
    ") -> TrainSetup:\n",
    "    \"\"\"\n",
    "    Creates a complete setup for training, given all necessary parameter from a runner (seefcdd.runners.bases.py).\n",
    "    This includes loading networks, datasets, data loaders, optimizers, and learning rate schedulers.\n",
    "    :param dataset: dataset identifier string (see :data:`fcdd.datasets.DS_CHOICES`).\n",
    "    :param datadir: directory where the datasets are found or to be downloaded to.\n",
    "    :param logdir: directory where log data is to be stored.\n",
    "    :param net: network model identifier string (see :func:`fcdd.models.choices`).\n",
    "    :param bias: whether to use bias in the network layers.\n",
    "    :param learning_rate: initial learning rate.\n",
    "    :param weight_decay: weight decay (L2 penalty) regularizer.\n",
    "    :param lr_sched_param: learning rate scheduler parameters. Format depends on the scheduler type.\n",
    "        For 'milestones' needs to have at least two elements, the first corresponding to the factor\n",
    "        the learning rate is decreased by at each milestone, the rest corresponding to milestones (epochs).\n",
    "        For 'lambda' needs to have exactly one element, i.e. the factor the learning rate is decreased by\n",
    "        at each epoch.\n",
    "    :param batch_size: batch size, i.e. number of data samples that are returned per iteration of the data loader.\n",
    "    :param optimizer_type: optimizer type, needs to be one of {'sgd', 'adam'}.\n",
    "    :param scheduler_type: learning rate scheduler type, needs to be one of {'lambda', 'milestones'}.\n",
    "    :param preproc: data preprocessing pipeline identifier string (see :data:`fcdd.datasets.PREPROC_CHOICES`).\n",
    "    :param supervise_mode: the type of generated artificial anomalies.\n",
    "        See :meth:`fcdd.datasets.bases.TorchvisionDataset._generate_artificial_anomalies_train_set`.\n",
    "    :param nominal_label: the label that is to be returned to mark nominal samples.\n",
    "    :param online_supervision: whether to sample anomalies online in each epoch,\n",
    "        or offline before training (same for all epochs in this case).\n",
    "    :param oe_limit: limits the number of different anomalies in case of Outlier Exposure (defined in noise_mode).\n",
    "    :param noise_mode: the type of noise used, see :mod:`fcdd.datasets.noise_mode`.\n",
    "    :param workers: how many subprocesses to use for data loading.\n",
    "    :param quantile: the quantile that is used to normalize the generated heatmap images.\n",
    "    :param resdown: the maximum resolution of logged images, images will be downsampled if necessary.\n",
    "    :param gauss_std: a constant value for the standard deviation of the Gaussian kernel used for upsampling and\n",
    "        blurring, the default value is determined by :func:`fcdd.datasets.noise.kernel_size_to_std`.\n",
    "    :param blur_heatmaps: whether to blur heatmaps.\n",
    "    :param cuda: whether to use GPU.\n",
    "    :param config: some config text that is to be stored in the config.txt file.\n",
    "    :param log_start_time: the start time of the experiment.\n",
    "    :param normal_class: the class that is to be considered nominal.\n",
    "    :return: a dictionary containing all necessary parameters to be passed to a Trainer instance.\n",
    "    \"\"\"\n",
    "    assert supervise_mode in SUPERVISE_MODES, 'unknown supervise mode: {}'.format(supervise_mode)\n",
    "    assert noise_mode in NOISE_MODES, 'unknown noise mode: {}'.format(noise_mode)\n",
    "    \n",
    "    device = torch.device('cuda:0') if cuda else torch.device('cpu')\n",
    "    \n",
    "    logger = Logger(\n",
    "        logdir=logdir, \n",
    "        exp_start_time=log_start_time,\n",
    "    )\n",
    "    \n",
    "    ds = load_dataset(\n",
    "        dataset_name=dataset,\n",
    "        data_path=datadir,\n",
    "        normal_class=normal_class,\n",
    "        preproc=preproc,   \n",
    "        supervise_mode=supervise_mode,\n",
    "        noise_mode=noise_mode,\n",
    "        online_supervision=online_supervision,\n",
    "        nominal_label=nominal_label,\n",
    "        oe_limit=oe_limit,\n",
    "        logger=logger,\n",
    "    )\n",
    "    \n",
    "    loaders = ds.loaders(\n",
    "        batch_size=batch_size, \n",
    "        num_workers=workers\n",
    "    )\n",
    "    \n",
    "    net = load_nets(name=net, in_shape=ds.shape, bias=bias)\n",
    "    net = net.to(device)\n",
    "\n",
    "    optimizer, scheduler = pick_opt_sched(\n",
    "        net=net, \n",
    "        lr=learning_rate, \n",
    "        wdk=weight_decay, \n",
    "        sched_params=lr_sched_param, \n",
    "        opt=optimizer_type, \n",
    "        sched=scheduler_type,\n",
    "    )\n",
    "    \n",
    "    logger.save_params(net, config)\n",
    "    \n",
    "    if not hasattr(ds, 'nominal_label') or ds.nominal_label < ds.anomalous_label:\n",
    "        ds_order = ['norm', 'anom']\n",
    "    else:\n",
    "        ds_order = ['anom', 'norm']\n",
    "        \n",
    "    images = ds.preview(percls=20, train=True)\n",
    "    \n",
    "    rowheaders = (\n",
    "        ds_order \n",
    "        if not isinstance(ds.train_set, GTMapADDataset) else \n",
    "        [*ds_order, '', *['gtno' if s == 'norm' else 'gtan' for s in ds_order]]\n",
    "    )\n",
    "        \n",
    "    logger.imsave(\n",
    "        name='ds_preview', \n",
    "        tensors=torch.cat([*images]), \n",
    "        nrow=images.size(1),\n",
    "        rowheaders=rowheaders,\n",
    "    )\n",
    "    \n",
    "    return TrainSetup(\n",
    "        net=net, \n",
    "        dataset_loaders=loaders, \n",
    "        opt=optimizer, \n",
    "        sched=scheduler, \n",
    "        logger=logger,\n",
    "        device=device, \n",
    "        quantile=quantile, \n",
    "        resdown=resdown,\n",
    "        gauss_std=gauss_std, \n",
    "        blur_heatmaps=blur_heatmaps,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# trainer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BaseADTrainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "import os.path as pt\n",
    "from abc import abstractmethod, ABC\n",
    "from typing import List, Tuple\n",
    "from torch import Tensor\n",
    "from torch.optim.lr_scheduler import _LRScheduler\n",
    "from torch.optim.optimizer import Optimizer\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "from torch.utils.data.dataset import Dataset\n",
    "import collections\n",
    "import os.path as pt\n",
    "from abc import abstractmethod, ABC\n",
    "from typing import List, Tuple\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from fcdd.datasets.bases import GTMapADDataset\n",
    "from fcdd.datasets.noise import kernel_size_to_std\n",
    "from fcdd.models.bases import BaseNet, ReceptiveNet\n",
    "from fcdd.training import balance_labels\n",
    "from fcdd.util.logging import colorize as colorize_img, Logger\n",
    "from kornia import gaussian_blur2d\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "from torch import Tensor\n",
    "from torch.optim.lr_scheduler import _LRScheduler\n",
    "from torch.optim.optimizer import Optimizer\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "from torch.utils.data.dataset import Dataset\n",
    "\n",
    "\n",
    "\n",
    "class BaseADTrainer(ABC):\n",
    "    \n",
    "    def __init__(\n",
    "        self, \n",
    "        net: BaseNet, \n",
    "        opt: Optimizer, \n",
    "        sched: _LRScheduler, \n",
    "        dataset_loaders: Tuple[DataLoader, DataLoader],\n",
    "        logger: Logger, \n",
    "        objective: str, \n",
    "        gauss_std: float, \n",
    "        quantile: float, \n",
    "        resdown: int, \n",
    "        blur_heatmaps=False,\n",
    "        device='cuda:0',\n",
    "        **kwargs\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Anomaly detection trainer that defines a test phase where scores are computed and heatmaps are generated.\n",
    "        The train method is modified to be able to handle ground-truth maps.\n",
    "        :param net: some neural network instance\n",
    "        :param opt: optimizer.\n",
    "        :param sched: learning rate scheduler.\n",
    "        :param dataset_loaders:\n",
    "        :param logger: some logger.\n",
    "        :param device: some torch device, either cpu or gpu.\n",
    "        :param gauss_std: a constant value for the standard deviation of the Gaussian kernel used for upsampling and\n",
    "            blurring, the default value is determined by :func:`fcdd.datasets.noise.kernel_size_to_std`.\n",
    "        :param quantile: the quantile that is used to normalize the generated heatmap images.\n",
    "        :param resdown: the maximum resolution of logged images, images will be downsampled if necessary.\n",
    "        :param blur_heatmaps: whether to blur heatmaps.\n",
    "        \"\"\"\n",
    "        self.net = net\n",
    "        self.opt = opt\n",
    "        self.sched = sched\n",
    "        self.train_loader, self.test_loader = dataset_loaders\n",
    "        self.logger = logger\n",
    "        self.device = device\n",
    "        self.objective = objective\n",
    "        self.gauss_std = gauss_std\n",
    "        self.quantile = quantile\n",
    "        self.resdown = resdown\n",
    "        self.blur_heatmaps = blur_heatmaps\n",
    "        \n",
    "    @abstractmethod\n",
    "    def loss(self, outs: Tensor, ins: Tensor, labels: Tensor, gtmaps: Tensor = None, reduce='mean'):\n",
    "        pass\n",
    "        \n",
    "    def load(self, path: str, cpu=False) -> int:\n",
    "        \"\"\" Loads a snapshot of the training state, including network weights \"\"\"\n",
    "        if cpu:\n",
    "            snapshot = torch.load(path, map_location=torch.device('cpu'))\n",
    "        else:\n",
    "            snapshot = torch.load(path)\n",
    "        net_state = snapshot.pop('net', None)\n",
    "        opt_state = snapshot.pop('opt', None)\n",
    "        sched_state = snapshot.pop('sched', None)\n",
    "        epoch = snapshot.pop('epoch', None)\n",
    "        if net_state is not None and self.net is not None:\n",
    "            self.net.load_state_dict(net_state)\n",
    "        if opt_state is not None and self.opt is not None:\n",
    "            self.opt.load_state_dict(opt_state)\n",
    "        if sched_state is not None and self.sched is not None:\n",
    "            self.sched.load_state_dict(sched_state)\n",
    "        print('Loaded {}{}{} with starting epoch {} for {}'.format(\n",
    "            'net_state, ' if net_state else '', 'opt_state, ' if opt_state else '',\n",
    "            'sched_state' if sched_state else '', epoch, str(self.__class__)[8:-2]\n",
    "        ))\n",
    "        return epoch\n",
    "\n",
    "    def anomaly_score(self, loss: Tensor) -> Tensor:\n",
    "        \"\"\" This assumes the loss is already the anomaly score. If this is not the case, reimplement the method! \"\"\"\n",
    "        return loss\n",
    "\n",
    "    def reduce_ascore(self, ascore: Tensor) -> Tensor:\n",
    "        \"\"\" Reduces the anomaly score to be a score per image (detection). \"\"\"\n",
    "        return ascore.reshape(ascore.size(0), -1).mean(1)\n",
    "\n",
    "    def reduce_pixelwise_ascore(self, ascore: Tensor) -> Tensor:\n",
    "        \"\"\" Reduces the anomaly score to be a score per pixel (explanation). \"\"\"\n",
    "        return ascore.mean(1).unsqueeze(1)\n",
    "\n",
    "    def train(self, epochs: int, acc_batches=1, wandb=None) -> BaseNet:\n",
    "        \"\"\"\n",
    "        Does epochs many full iteration of the data loader and trains the network with the data using self.loss.\n",
    "        Supports ground-truth maps, logs losses for\n",
    "        nominal and anomalous samples separately, and introduces another parameter to\n",
    "        accumulate batches for faster data loading.\n",
    "        :param epochs: number of full data loader iterations to train.\n",
    "        :param acc_batches: To speed up data loading, this determines the number of batches that are accumulated\n",
    "            before forwarded through the network. For instance, acc_batches=2 iterates the data loader two times,\n",
    "            concatenates the batches, and passes this to the network. This has no impact on the performance\n",
    "            if the batch size is reduced accordingly (e.g. one half in this example), but can decrease training time.\n",
    "        :return: the trained network\n",
    "        \"\"\"\n",
    "        \n",
    "        assert 0 < acc_batches and isinstance(acc_batches, int)\n",
    "        \n",
    "        self.net = self.net.to(self.device).train()\n",
    "        \n",
    "        for epoch in range(epochs):\n",
    "            \n",
    "            acc_data, acc_counter = [], 1\n",
    "            \n",
    "            for n_batch, data in enumerate(self.train_loader):\n",
    "                \n",
    "                if acc_counter < acc_batches and n_batch < len(self.train_loader) - 1:\n",
    "                    acc_data.append(data)\n",
    "                    acc_counter += 1\n",
    "                    continue\n",
    "                elif acc_batches > 1:\n",
    "                    acc_data.append(data)\n",
    "                    data = [torch.cat(d) for d in zip(*acc_data)]\n",
    "                    acc_data, acc_counter = [], 1\n",
    "\n",
    "                if isinstance(self.train_loader.dataset, GTMapADDataset):\n",
    "                    inputs, labels, gtmaps = data\n",
    "                    gtmaps = gtmaps.to(self.device)\n",
    "                else:\n",
    "                    inputs, labels = data\n",
    "                    gtmaps = None\n",
    "                    \n",
    "                inputs = inputs.to(self.device)\n",
    "                self.opt.zero_grad()\n",
    "                outputs = self.net(inputs)\n",
    "                loss = self.loss(outputs, inputs, labels, gtmaps)\n",
    "                loss.backward()\n",
    "                self.opt.step()\n",
    "                with torch.no_grad():\n",
    "                    info = {}\n",
    "                    if len(set(labels.tolist())) > 1:\n",
    "                        swloss = self.loss(outputs, inputs, labels, gtmaps, reduce='none')\n",
    "                        swloss = swloss.reshape(swloss.size(0), -1).mean(-1)\n",
    "                        info = {'err_normal': swloss[labels == 0].mean(),\n",
    "                                'err_anomalous': swloss[labels != 0].mean()}\n",
    "                    self.logger.log(\n",
    "                        epoch, \n",
    "                        n_batch, \n",
    "                        len(self.train_loader), \n",
    "                        loss,\n",
    "                        infoprint='LR {} ID {}{}'.format(\n",
    "                            ['{:.0e}'.format(p['lr']) for p in self.opt.param_groups],\n",
    "                            str(self.__class__)[8:-2],\n",
    "                            ' NCLS {}'.format(self.train_loader.dataset.normal_classes)\n",
    "                            if hasattr(self.train_loader.dataset, 'normal_classes') else ''\n",
    "                        ),\n",
    "                        info=info\n",
    "                    )\n",
    "                    if wandb is not None:\n",
    "                        wandb.log(dict(\n",
    "                            epoch=epoch,\n",
    "                            epoch_percent=epoch / epochs,\n",
    "                            n_batch=n_batch,\n",
    "                            n_batch_percent=n_batch / len(self.train_loader),\n",
    "                            loss=loss.data.item(),\n",
    "                        ))\n",
    "            self.sched.step()\n",
    "\n",
    "\n",
    "\n",
    "        return self.net\n",
    "\n",
    "    def test(self, specific_viz_ids: Tuple[List[int], List[int]] = (), train_data=True, subdir='.') -> dict:\n",
    "        \"\"\"\n",
    "        Does a full iteration of the data loaders, remembers all data (i.e. inputs, labels, outputs, loss),\n",
    "        and computes scores and heatmaps with it. Scores and heatmaps are computed for both, the training\n",
    "        and the test data. For each, one heatmap picture is generated that contains (row-wise):\n",
    "            -   The first 20 nominal samples (label == 0, if nominal_label==1 this shows anomalies instead).\n",
    "            -   The first 20 anomalous samples (label == 1, if nominal_label==1 this shows nominal samples instead).\n",
    "                The :func:`reorder` takes care that the first anomalous test samples are not all from the same class.\n",
    "            -   The 10 most nominal rated samples from the nominal set on the left and\n",
    "                the 10 most anomalous rated samples from the nominal set on the right.\n",
    "            -   The 10 most nominal rated samples from the anomalous set on the left and\n",
    "                the 10 most anomalous  rated samples from the anomalous set on the right.\n",
    "        Additionally, for the test set only, four heatmap pictures are generated that show six samples with\n",
    "        increasing anomaly score from left to right. Thereby the leftmost heatmap shows the most nominal rated example\n",
    "        and the rightmost sample the most anomalous rated one. There are two heatmaps for the anomalous set and\n",
    "        two heatmaps for the nominal set. Both with either local normalization -- i.e. each heatmap is normalized\n",
    "        w.r.t itself only, there is a complete red and complete blue pixel in each heatmap -- or semi-global\n",
    "        normalization -- each heatmap is normalized w.r.t. to all heatmaps shown in the picture.\n",
    "        These four heatmap pictures are also stored as tensors in a 'tim' subdirectory for later usage.\n",
    "        The score computes AUC values and complete ROC curves for detection. It also computes explanation ROC curves\n",
    "        if ground-truth maps are available.\n",
    "\n",
    "        :param specific_viz_ids: in addition to the heatmaps generated above, this also generates heatmaps\n",
    "            for specific sample indices. The first element of specific_viz_ids is for nominal samples\n",
    "            and the second for anomalous ones. The resulting heatmaps are stored in a `specific_viz_ids` subdirectory.\n",
    "        :return: A dictionary of ROC results, each ROC result is again represented by a dictionary of the form: {\n",
    "                'tpr': [], 'fpr': [], 'ths': [], 'auc': int, ...\n",
    "            }.\n",
    "        \"\"\"\n",
    "        self.net = self.net.to(self.device).eval()\n",
    "\n",
    "        if train_data:\n",
    "            self.logger.print('Test training data...', fps=False)\n",
    "            labels, loss, anomaly_scores, imgs, outputs, gtmaps, grads = self._gather_data(\n",
    "                self.train_loader\n",
    "            )\n",
    "            self.heatmap_generation(labels, anomaly_scores, imgs, gtmaps, grads, name='train_heatmaps',)\n",
    "            \n",
    "        else:\n",
    "            self.logger.print('Test training data SKIPPED', fps=False)\n",
    "\n",
    "        self.logger.print('Test test data...', fps=False)\n",
    "        labels, loss, anomaly_scores, imgs, outputs, gtmaps, grads = self._gather_data(\n",
    "            self.test_loader,\n",
    "        )\n",
    "        \n",
    "        def reorder(labels: List[int], loss: Tensor, anomaly_scores: Tensor, imgs: Tensor, outputs: Tensor, gtmaps: Tensor,\n",
    "                    grads: Tensor, ds: Dataset = None) -> Tuple[List[int], Tensor, Tensor, Tensor, Tensor, Tensor, Tensor]:\n",
    "            \"\"\" returns all inputs in an identical new order if the dataset offers a predefined (random) order \"\"\"\n",
    "            if ds is not None and hasattr(ds, 'fixed_random_order'):\n",
    "                assert gtmaps is None, \\\n",
    "                    'original gtmaps loaded in score do not know order! Hence reordering is not allowed for GT datasets'\n",
    "                o = ds.fixed_random_order\n",
    "                labels = labels[o] if isinstance(labels, (Tensor, np.ndarray)) else np.asarray(labels)[o].tolist()\n",
    "                loss, anomaly_scores, imgs = loss[o], anomaly_scores[o], imgs[o]\n",
    "                outputs, gtmaps = outputs[o], gtmaps\n",
    "                grads = grads[o] if grads is not None else None\n",
    "            return labels, loss, anomaly_scores, imgs, outputs, gtmaps, grads\n",
    "        \n",
    "        labels, loss, anomaly_scores, imgs, outputs, gtmaps, grads = reorder(\n",
    "            labels, loss, anomaly_scores, imgs, outputs, gtmaps, grads, ds=self.test_loader.dataset\n",
    "        )\n",
    "        self.heatmap_generation(labels, anomaly_scores, imgs, gtmaps, grads, name='test_heatmaps',)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            sc = self.score(labels, anomaly_scores, imgs, outputs, gtmaps, grads, subdir=subdir)\n",
    "        return sc\n",
    "\n",
    "    def _gather_data(self, loader: DataLoader,\n",
    "                     gather_all=False) -> Tuple[List[int], Tensor, Tensor, Tensor, Tensor, Tensor, Tensor]:\n",
    "        all_labels, all_loss, all_anomaly_scores, all_imgs, all_outputs = [], [], [], [], []\n",
    "        all_gtmaps, all_grads = [], []\n",
    "        for n_batch, data in enumerate(loader):\n",
    "            if isinstance(loader.dataset, GTMapADDataset):\n",
    "                inputs, labels, gtmaps = data\n",
    "                all_gtmaps.append(gtmaps)\n",
    "            else:\n",
    "                inputs, labels = data\n",
    "            bk_inputs = inputs.detach().clone()\n",
    "            inputs = inputs.to(self.device)\n",
    "            if gather_all:\n",
    "                outputs, loss, anomaly_score, _ = self._regular_forward(inputs, labels)\n",
    "                inputs = bk_inputs.clone().to(self.device)\n",
    "                _, _, _, grads = self._grad_forward(inputs, labels)\n",
    "            elif self.objective == 'hsc':\n",
    "                outputs, loss, anomaly_score, grads = self._grad_forward(inputs, labels)\n",
    "            else:\n",
    "                outputs, loss, anomaly_score, grads = self._regular_forward(inputs, labels)\n",
    "            all_labels += labels.detach().cpu().tolist()\n",
    "            all_loss.append(loss.detach().cpu())\n",
    "            all_anomaly_scores.append(anomaly_score.detach().cpu())\n",
    "            all_imgs.append(inputs.detach().cpu())\n",
    "            all_outputs.append(outputs.detach().cpu())\n",
    "            if grads is not None:\n",
    "                all_grads.append(grads.detach().cpu())\n",
    "            self.logger.print(\n",
    "                'TEST {:04d}/{:04d} ID {}{}'.format(\n",
    "                    n_batch, len(loader), str(self.__class__)[8:-2],\n",
    "                    ' NCLS {}'.format(loader.dataset.normal_classes)\n",
    "                    if hasattr(loader.dataset, 'normal_classes') else ''\n",
    "                ),\n",
    "                fps=True\n",
    "            )\n",
    "        all_imgs = torch.cat(all_imgs)\n",
    "        all_outputs = torch.cat(all_outputs)\n",
    "        all_gtmaps = torch.cat(all_gtmaps) if len(all_gtmaps) > 0 else None\n",
    "        all_loss = torch.cat(all_loss)\n",
    "        all_anomaly_scores = torch.cat(all_anomaly_scores)\n",
    "        all_grads = torch.cat(all_grads) if len(all_grads) > 0 else None\n",
    "        ret = (\n",
    "            all_labels, all_loss, all_anomaly_scores, all_imgs, all_outputs, all_gtmaps,\n",
    "            all_grads\n",
    "        )\n",
    "        return ret\n",
    "\n",
    "    def _regular_forward(self, inputs: Tensor, labels: Tensor) -> Tuple[Tensor, Tensor, Tensor, Tensor]:\n",
    "        with torch.no_grad():\n",
    "            outputs = self.net(inputs)\n",
    "            loss = self.loss(outputs, inputs, labels, reduce='none')\n",
    "            anomaly_score = self.anomaly_score(loss)\n",
    "            grads = None\n",
    "        return outputs, loss, anomaly_score, grads\n",
    "\n",
    "    def _grad_forward(self, inputs: Tensor, labels: Tensor) -> Tuple[Tensor, Tensor, Tensor, Tensor]:\n",
    "        inputs.requires_grad = True\n",
    "        outputs = self.net(inputs)\n",
    "        loss = self.loss(outputs, inputs, labels, reduce='none')\n",
    "        anomaly_score = self.anomaly_score(loss)\n",
    "        grads = self.net.get_grad_heatmap(loss, inputs)\n",
    "        inputs.requires_grad = False\n",
    "        self.opt.zero_grad()\n",
    "        return outputs, loss, anomaly_score, grads\n",
    "\n",
    "    def score(self, labels: List[int], ascores: Tensor, imgs: Tensor, outs: Tensor, gtmaps: Tensor = None,\n",
    "              grads: Tensor = None, subdir='.') -> dict:\n",
    "        \"\"\"\n",
    "        Computes the ROC curves and the AUC for detection performance.\n",
    "        Also computes those for the explanation performance if ground-truth maps are available.\n",
    "        :param labels: labels\n",
    "        :param ascores: anomaly scores\n",
    "        :param imgs: input images\n",
    "        :param outs: outputs of the neural network\n",
    "        :param gtmaps: ground-truth maps (can be None)\n",
    "        :param grads: gradients of anomaly scores w.r.t. inputs (can be None)\n",
    "        :param subdir: subdirectory to store the data in (plots and numbers)\n",
    "        :return:  A dictionary of ROC results, each ROC result is again represented by a dictionary of the form: {\n",
    "                'tpr': [], 'fpr': [], 'ths': [], 'auc': int, ...\n",
    "            }.\n",
    "        \"\"\"\n",
    "        # Logging\n",
    "        self.logger.print('Computing test score...')\n",
    "        if torch.isnan(ascores).sum() > 0:\n",
    "            self.logger.logtxt('Could not compute test scores, since anomaly scores contain nan values!!!', True)\n",
    "            return None\n",
    "        red_ascores = self.reduce_ascore(ascores).tolist()\n",
    "        std = self.gauss_std\n",
    "\n",
    "        # Overall ROC for sample-wise anomaly detection\n",
    "        fpr, tpr, thresholds = roc_curve(labels, red_ascores)\n",
    "        roc_score = roc_auc_score(labels, red_ascores)\n",
    "        roc_res = {'tpr': tpr, 'fpr': fpr, 'ths': thresholds, 'auc': roc_score}\n",
    "        self.logger.single_plot(\n",
    "            'roc_curve', tpr, fpr, xlabel='false positive rate', ylabel='true positive rate',\n",
    "            legend=['auc={}'.format(roc_score)], subdir=subdir\n",
    "        )\n",
    "        self.logger.single_save('roc', roc_res, subdir=subdir)\n",
    "        self.logger.logtxt('##### ROC TEST SCORE {} #####'.format(roc_score), print=True)\n",
    "\n",
    "        # GTMAPS pixel-wise anomaly detection = explanation performance\n",
    "        gtmap_roc_res, gtmap_prc_res = None, None\n",
    "        use_grads = grads is not None\n",
    "        if gtmaps is not None:\n",
    "            try:\n",
    "                self.logger.print('Computing GT test score...')\n",
    "                ascores = self.reduce_pixelwise_ascore(ascores) if not use_grads else grads\n",
    "                gtmaps = self.test_loader.dataset.dataset.get_original_gtmaps_normal_class()\n",
    "                if isinstance(self.net, ReceptiveNet):  # Receptive field upsampling for FCDD nets\n",
    "                    ascores = self.net.receptive_upsample(ascores, std=std)\n",
    "                # Further upsampling for original dataset size\n",
    "                ascores = torch.nn.functional.interpolate(ascores, (gtmaps.shape[-2:]))\n",
    "                flat_gtmaps, flat_ascores = gtmaps.reshape(-1).int().tolist(), ascores.reshape(-1).tolist()\n",
    "\n",
    "                gtfpr, gttpr, gtthresholds = roc_curve(flat_gtmaps, flat_ascores)\n",
    "                gt_roc_score = roc_auc_score(flat_gtmaps, flat_ascores)\n",
    "                gtmap_roc_res = {'tpr': gttpr, 'fpr': gtfpr, 'ths': gtthresholds, 'auc': gt_roc_score}\n",
    "                self.logger.single_plot(\n",
    "                    'gtmap_roc_curve', gttpr, gtfpr, xlabel='false positive rate', ylabel='true positive rate',\n",
    "                    legend=['auc={}'.format(gt_roc_score)], subdir=subdir\n",
    "                )\n",
    "                self.logger.single_save(\n",
    "                    'gtmap_roc', gtmap_roc_res, subdir=subdir\n",
    "                )\n",
    "                self.logger.logtxt('##### GTMAP ROC TEST SCORE {} #####'.format(gt_roc_score), print=True)\n",
    "            except AssertionError as e:\n",
    "                self.logger.warning(f'Skipped computing the gtmap ROC score. {str(e)}')\n",
    "\n",
    "        return {'roc': roc_res, 'gtmap_roc': gtmap_roc_res}\n",
    "\n",
    "    def heatmap_generation(\n",
    "        self, \n",
    "        labels: List[int], \n",
    "        ascores: Tensor, \n",
    "        imgs: Tensor, \n",
    "        gtmaps: Tensor = None, \n",
    "        grads: Tensor = None, \n",
    "        show_per_cls: int = 20,\n",
    "        name='heatmaps', \n",
    "        subdir='.'\n",
    "    ):\n",
    "        minsamples = min(collections.Counter(labels).values())\n",
    "        lbls = torch.IntTensor(labels)\n",
    "\n",
    "        if minsamples < 2:\n",
    "            self.logger.warning(\n",
    "                f\"Heatmap '{name}' cannot be generated. For some labels there are too few samples!\", unique=False\n",
    "            )\n",
    "        else:\n",
    "            this_show_per_cls = min(show_per_cls, minsamples)\n",
    "            if this_show_per_cls % 2 != 0:\n",
    "                this_show_per_cls -= 1\n",
    "            # Evaluation Picture with 4 rows. Each row splits into 4 subrows with input-output-heatmap-gtm:\n",
    "            # (1) 20 first nominal samples (2) 20 first anomalous samples\n",
    "            # (3) 10 most nominal nominal samples - 10 most anomalous nominal samples\n",
    "            # (4) 10 most nominal anomalies - 10 most anomalous anomalies\n",
    "            idx = []\n",
    "            for l in sorted(set(labels)):\n",
    "                idx.extend((lbls == l).nonzero().squeeze(-1).tolist()[:this_show_per_cls])\n",
    "            rascores = self.reduce_ascore(ascores)\n",
    "            k = max(this_show_per_cls // 2, 1)\n",
    "            for l in sorted(set(labels)):\n",
    "                lid = set((lbls == l).nonzero().squeeze(-1).tolist())\n",
    "                sort = [\n",
    "                    i for i in np.argsort(rascores.detach().reshape(rascores.size(0), -1).sum(1)).tolist() if i in lid\n",
    "                ]\n",
    "                idx.extend([*sort[:k], *sort[-k:]])\n",
    "            self._create_heatmaps_picture(\n",
    "                idx, name, imgs.shape, subdir, this_show_per_cls, imgs, ascores, grads, gtmaps, labels\n",
    "            )\n",
    "\n",
    "        # Concise paper picture: Samples grow from most nominal to most anomalous (equidistant).\n",
    "        # 2 versions: with local normalization and semi-global normalization\n",
    "        if 'train' not in name:\n",
    "            res = self.resdown * 2  # increase resolution limit because there are only a few heatmaps shown here\n",
    "            rascores = self.reduce_ascore(ascores)\n",
    "            inpshp = imgs.shape\n",
    "            for l in sorted(set(labels)):\n",
    "                lid = set((torch.from_numpy(np.asarray(labels)) == l).nonzero().squeeze(-1).tolist())\n",
    "                if len(lid) < 1:\n",
    "                    break\n",
    "                k = min(show_per_cls // 3, len(lid))\n",
    "                sort = [\n",
    "                    i for i in np.argsort(rascores.detach().reshape(rascores.size(0), -1).sum(1)).tolist() if i in lid\n",
    "                ]\n",
    "                splits = np.array_split(sort, k)\n",
    "                idx = [s[int(n / (k - 1) * len(s)) if n != len(splits) - 1 else -1] for n, s in enumerate(splits)]\n",
    "                self.logger.logtxt(\n",
    "                    'Interpretation visualization paper image {} indicies for label {}: {}'\n",
    "                    .format('{}_paper_lbl{}'.format(name, l), l, idx)\n",
    "                )\n",
    "                self._create_singlerow_heatmaps_picture(\n",
    "                    idx, name, inpshp, l, subdir, res, imgs, ascores, grads, gtmaps, labels\n",
    "                )\n",
    "\n",
    "    def _create_heatmaps_picture(self, idx: List[int], name: str, inpshp: torch.Size, subdir: str,\n",
    "                                 nrow: int, imgs: Tensor, ascores: Tensor, grads: Tensor, gtmaps: Tensor,\n",
    "                                 labels: List[int], norm: str = 'global'):\n",
    "        \"\"\"\n",
    "        Creates a picture of inputs, heatmaps (either based on ascores or grads, if grads is not None),\n",
    "        and ground-truth maps (if not None, otherwise omitted). Each row contains nrow many samples.\n",
    "        One row contains always only one of {input, heatmaps, ground-truth maps}.\n",
    "        The order of rows thereby is (1) inputs (2) heatmaps (3) ground-truth maps (4) blank.\n",
    "        For instance, for 20 samples and nrow=10, the picture would show:\n",
    "            - 10 inputs\n",
    "            - 10 corresponding heatmaps\n",
    "            - 10 corresponding ground-truth maps\n",
    "            - blank\n",
    "            - 10 inputs\n",
    "            - 10 corresponding heatmaps\n",
    "            - 10 corresponding ground-truth maps\n",
    "        :param idx: limit the inputs (and corresponding other rows) to these indices.\n",
    "        :param name: name to be used to store the picture.\n",
    "        :param inpshp: the input shape (heatmaps will be resized to this).\n",
    "        :param subdir: some subdirectory to store the data in.\n",
    "        :param nrow: number of images per row.\n",
    "        :param imgs: the input images.\n",
    "        :param ascores: anomaly scores.\n",
    "        :param grads: gradients.\n",
    "        :param gtmaps: ground-truth maps.\n",
    "        :param norm: what type of normalization to apply.\n",
    "            None: no normalization.\n",
    "            'local': normalizes each heatmap w.r.t. itself only.\n",
    "            'global': normalizes each heatmap w.r.t. all heatmaps available (without taking idx into account),\n",
    "                though it is ensured to consider equally many anomalous and nominal samples (if there are e.g. more\n",
    "                nominal samples, randomly chosen nominal samples are ignored to match the correct amount).\n",
    "            'semi-global: normalizes each heatmap w.r.t. all heatmaps chosen in idx.\n",
    "        \"\"\"\n",
    "        number_of_rows = int(np.ceil(len(idx) / nrow))\n",
    "        rows = []\n",
    "        for s in range(number_of_rows):\n",
    "            rows.append(self._image_processing(imgs[idx][s * nrow:s * nrow + nrow], inpshp, maxres=self.resdown, qu=1))\n",
    "            if self.objective != 'hsc':\n",
    "                rows.append(\n",
    "                    self._image_processing(\n",
    "                        ascores[idx][s * nrow:s * nrow + nrow], inpshp, maxres=self.resdown, qu=self.quantile,\n",
    "                        colorize=True, ref=balance_labels(ascores, labels, False) if norm == 'global' else ascores[idx],\n",
    "                        norm=norm.replace('semi_', ''),  # semi case is handled in the line above\n",
    "                    )\n",
    "                )\n",
    "            if grads is not None:\n",
    "                rows.append(\n",
    "                    self._image_processing(\n",
    "                        grads[idx][s * nrow:s * nrow + nrow], inpshp, self.blur_heatmaps,\n",
    "                        self.resdown, qu=self.quantile,\n",
    "                        colorize=True, ref=balance_labels(grads, labels, False) if norm == 'global' else grads[idx],\n",
    "                        norm=norm.replace('semi_', ''),  # semi case is handled in the line above\n",
    "                    )\n",
    "                )\n",
    "            if gtmaps is not None:\n",
    "                rows.append(\n",
    "                    self._image_processing(\n",
    "                        gtmaps[idx][s * nrow:s * nrow + nrow], inpshp, maxres=self.resdown, norm=None\n",
    "                    )\n",
    "                )\n",
    "            rows.append(torch.zeros_like(rows[-1]))\n",
    "        name = '{}_{}'.format(name, norm)\n",
    "        self.logger.imsave(name, torch.cat(rows), nrow=nrow, scale_mode='none', subdir=subdir)\n",
    "\n",
    "    def _create_singlerow_heatmaps_picture(self, idx: List[int], name: str, inpshp: torch.Size, lbl: int, subdir: str,\n",
    "                                           res: int, imgs: Tensor, ascores: Tensor, grads: Tensor, gtmaps: Tensor,\n",
    "                                           labels: List[int]):\n",
    "        \"\"\"\n",
    "        Creates a picture of inputs, heatmaps (either based on ascores or grads, if grads is not None),\n",
    "        and ground-truth maps (if not None, otherwise omitted).\n",
    "        Row-wise: (1) inputs (2) heatmaps (3) ground-truth maps.\n",
    "        Creates one version with local normalization and one with semi_global normalization.\n",
    "        :param idx: limit the inputs (and corresponding other rows) to these indices.\n",
    "        :param name: name to be used to store the picture.\n",
    "        :param inpshp: the input shape (heatmaps will be resized to this).\n",
    "        :param lbl: label of samples (indices), only used for naming.\n",
    "        :param subdir: some subdirectory to store the data in.\n",
    "        :param res: maximum allowed resolution in pixels (images are downsampled if they exceed this threshold).\n",
    "        :param imgs: the input images.\n",
    "        :param ascores: anomaly scores.\n",
    "        :param grads: gradients.\n",
    "        :param gtmaps: ground-truth maps.\n",
    "        \"\"\"\n",
    "        for norm in ['local', 'global']:\n",
    "            rows = [self._image_processing(imgs[idx], inpshp, maxres=res, qu=1)]\n",
    "            if self.objective != 'hsc':\n",
    "                rows.append(\n",
    "                    self._image_processing(\n",
    "                        ascores[idx], inpshp, maxres=res, colorize=True,\n",
    "                        ref=balance_labels(ascores, labels, False) if norm == 'global' else None,\n",
    "                        norm=norm.replace('semi_', ''),  # semi case is handled in the line above\n",
    "                    )\n",
    "                )\n",
    "            if grads is not None:\n",
    "                rows.append(\n",
    "                    self._image_processing(\n",
    "                        grads[idx], inpshp, self.blur_heatmaps, res, colorize=True,\n",
    "                        ref=balance_labels(grads, labels, False) if norm == 'global' else None,\n",
    "                        norm=norm.replace('semi_', ''),  # semi case is handled in the line above\n",
    "                    )\n",
    "                )\n",
    "            if gtmaps is not None:\n",
    "                rows.append(self._image_processing(gtmaps[idx], inpshp, maxres=res, norm=None))\n",
    "            tim = torch.cat(rows)\n",
    "            imname = '{}_paper_{}_lbl{}'.format(name, norm, lbl)\n",
    "            self.logger.single_save(imname, torch.stack(rows), subdir=pt.join('tims', subdir))\n",
    "            self.logger.imsave(imname, tim, nrow=len(idx), scale_mode='none', subdir=subdir)\n",
    "\n",
    "    def _image_processing(self, imgs: Tensor, input_shape: torch.Size, blur: bool = False, maxres: int = 64,\n",
    "                          qu: float = None, norm: str = 'local', colorize: bool = False, ref: Tensor = None,\n",
    "                          cmap: str = 'jet') -> Tensor:\n",
    "        \"\"\"\n",
    "        Applies basic image processing techniques, including resizing, blurring, colorizing, and normalizing.\n",
    "        The resize operation resizes the images automatically to match the input_shape. Other transformations\n",
    "        are optional. Can be used to create pseudocolored heatmaps!\n",
    "        :param imgs: a tensor of some images.\n",
    "        :param input_shape: the shape of the inputs images the data loader returns.\n",
    "        :param blur: whether to blur the image (has no effect for FCDD anomaly scores, where the\n",
    "            anomaly scores are upsampled using a Gaussian kernel anyway).\n",
    "        :param maxres: maximum allowed resolution in pixels (images are downsampled if they exceed this threshold).\n",
    "        :param norm: what type of normalization to apply.\n",
    "            None: no normalization.\n",
    "            'local': normalizes each image w.r.t. itself only.\n",
    "            'global': normalizes each image w.r.t. to ref (ref defaults to imgs).\n",
    "        :param qu: quantile used for normalization, qu=1 yields the typical 0-1 normalization.\n",
    "        :param colorize: whether to colorize grayscaled images using colormaps (-> pseudocolored heatmaps!).\n",
    "        :param ref: a tensor of images used for global normalization (defaults to imgs).\n",
    "        :param cmap: the colormap that is used to colorize grayscaled images.\n",
    "        :return: transformed tensor of images\n",
    "        \"\"\"\n",
    "        imgs = imgs.detach().clone()\n",
    "        assert imgs.dim() == len(input_shape) == 4  # n x c x h x w\n",
    "        std = self.gauss_std\n",
    "        if qu is None:\n",
    "            qu = self.quantile\n",
    "\n",
    "        # upsample if necessary (img.shape != input_shape)\n",
    "        if imgs.shape[2:] != input_shape[2:]:\n",
    "            assert isinstance(self.net, ReceptiveNet), \\\n",
    "                'Some images are not of full resolution, and network is not a receptive net. This should not occur! '\n",
    "            imgs = self.net.receptive_upsample(imgs, reception=True, std=std)\n",
    "\n",
    "        # blur if requested\n",
    "        if blur:\n",
    "            if isinstance(self.net, ReceptiveNet):\n",
    "                r = self.net.reception['r']\n",
    "            elif self.objective == 'hsc':\n",
    "                r = self.net.fcdd_cls(self.net.in_shape, bias=True).reception['r']\n",
    "            elif self.objective == 'ae':\n",
    "                enc = self.net.encoder\n",
    "                if isinstance(enc, ReceptiveNet):\n",
    "                    r = enc.reception['r']\n",
    "                else:\n",
    "                    r = enc.fcdd_cls(enc.in_shape, bias=True).reception['r']\n",
    "            else:\n",
    "                raise NotImplementedError()\n",
    "            r = (r - 1) if r % 2 == 0 else r\n",
    "            std = std or kernel_size_to_std(r)\n",
    "            imgs = gaussian_blur2d(imgs, (r,) * 2, (std,) * 2)\n",
    "\n",
    "        # downsample if resolution exceeds the limit given with maxres\n",
    "        if maxres < max(imgs.shape[2:]):\n",
    "            assert imgs.shape[-2] == imgs.shape[-1], 'Image provided is no square!'\n",
    "            imgs = F.interpolate(imgs, (maxres, maxres), mode='nearest')\n",
    "\n",
    "        # apply requested normalization\n",
    "        if norm is not None:\n",
    "            apply_norm = {\n",
    "                'local': self.__local_norm, 'global': self.__global_norm\n",
    "            }\n",
    "            imgs = apply_norm[norm](imgs, qu, ref)\n",
    "\n",
    "        # if image is grayscaled, colorize, i.e. provide a pseudocolored heatmap!\n",
    "        if colorize:\n",
    "            imgs = imgs.mean(1).unsqueeze(1)\n",
    "            imgs = colorize_img([imgs, ], norm=False, cmap=cmap)[0]\n",
    "        else:\n",
    "            imgs = imgs.repeat(1, 3, 1, 1) if imgs.size(1) == 1 else imgs\n",
    "\n",
    "        return imgs\n",
    "\n",
    "    @staticmethod\n",
    "    def __global_norm(imgs: Tensor, qu: int, ref: Tensor = None) -> Tensor:\n",
    "        \"\"\"\n",
    "        Applies a global normalization of tensor, s.t. the highest value of the complete tensor is 1 and\n",
    "        the lowest value is >= zero. Uses a non-linear normalization based on quantiles as explained in the appendix\n",
    "        of the paper.\n",
    "        :param imgs: images tensor\n",
    "        :param qu: quantile used\n",
    "        :param ref: if this is None, normalizes w.r.t. to imgs, otherwise normalizes w.r.t. to ref.\n",
    "        \"\"\"\n",
    "        ref = ref if ref is not None else imgs\n",
    "        imgs.sub_(ref.min())\n",
    "        ref = ref.sub(ref.min())\n",
    "        quantile = ref.reshape(-1).kthvalue(int(qu * ref.reshape(-1).size(0)))[0]  # qu% are below that\n",
    "        imgs.div_(quantile)  # (1 - qu)% values will end up being out of scale ( > 1)\n",
    "        plosses = imgs.clamp(0, 1)  # clamp those\n",
    "        return plosses\n",
    "\n",
    "    @staticmethod\n",
    "    def __local_norm(imgs: Tensor, qu: int, ref: Tensor = None) -> Tensor:\n",
    "        \"\"\"\n",
    "        Applies a local normalization of tensor, s.t. the highest value of each element (dim=0) in the tensor is 1 and\n",
    "        the lowest value is >= zero. Uses a non-linear normalization based on quantiles as explained in the appendix\n",
    "        of the paper.\n",
    "        :param imgs: images tensor\n",
    "        :param qu: quantile used\n",
    "        \"\"\"\n",
    "        imgs.sub_(imgs.reshape(imgs.size(0), -1).min(1)[0][(...,) + (None,) * (imgs.dim() - 1)])\n",
    "        quantile = imgs.reshape(imgs.size(0), -1).kthvalue(\n",
    "            int(qu * imgs.reshape(imgs.size(0), -1).size(1)), dim=1\n",
    "        )[0]  # qu% are below that\n",
    "        imgs.div_(quantile[(...,) + (None,) * (imgs.dim() - 1)])\n",
    "        imgs = imgs.clamp(0, 1)  # clamp those\n",
    "        return imgs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FCDDTrainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FCDDTrainer(BaseADTrainer):\n",
    "    def loss(self, outs: Tensor, ins: Tensor, labels: Tensor, gtmaps: Tensor = None, reduce='mean'):\n",
    "        \"\"\" computes the FCDD loss \"\"\"\n",
    "        assert reduce in ['mean', 'none']\n",
    "        if self.objective in ['fcdd']:\n",
    "            loss = self.__fcdd_loss(outs, ins, labels, gtmaps, reduce)\n",
    "        else:\n",
    "            raise NotImplementedError('Objective {} is not defined yet.'.format(self.objective))\n",
    "        return loss\n",
    "\n",
    "    def __fcdd_loss(self, outs: Tensor, ins: Tensor, labels: Tensor, gtmaps: Tensor, reduce: str):\n",
    "        loss = outs ** 2\n",
    "        loss = (loss + 1).sqrt() - 1\n",
    "        if gtmaps is None and len(set(labels.tolist())) > 1:\n",
    "            loss = self.__supervised_loss(loss, labels)\n",
    "        elif gtmaps is not None and isinstance(self.net, FCDDNet):\n",
    "            loss = self.__gt_loss(loss, gtmaps)\n",
    "        return loss.mean() if reduce == 'mean' else loss\n",
    "\n",
    "    def __supervised_loss(self, loss: Tensor, labels: Tensor):\n",
    "        if self.net.training:\n",
    "            loss = loss.reshape(labels.size(0), -1).mean(-1)\n",
    "            norm = loss[labels == 0]\n",
    "            anom = (-(((1 - (-loss[labels == 1]).exp()) + 1e-31).log()))\n",
    "            loss[(1-labels).nonzero().squeeze()] = norm\n",
    "            loss[labels.nonzero().squeeze()] = anom\n",
    "        else:\n",
    "            loss = loss\n",
    "        return loss\n",
    "\n",
    "    def __gt_loss(self, loss: Tensor, gtmaps: Tensor):\n",
    "        if self.net.training:\n",
    "            std = self.gauss_std\n",
    "            loss = self.net.receptive_upsample(loss, reception=True, std=std, cpu=False)\n",
    "            norm = (loss * (1 - gtmaps)).view(loss.size(0), -1).mean(-1)\n",
    "            exclude_complete_nominal_samples = ((gtmaps == 1).view(gtmaps.size(0), -1).sum(-1) > 0)\n",
    "            anom = torch.zeros_like(norm)\n",
    "            if exclude_complete_nominal_samples.sum() > 0:\n",
    "                a = (loss * gtmaps)[exclude_complete_nominal_samples]\n",
    "                anom[exclude_complete_nominal_samples] = (\n",
    "                    -(((1 - (-a.view(a.size(0), -1).mean(-1)).exp()) + 1e-31).log())\n",
    "                )\n",
    "            loss = norm + anom\n",
    "        else:\n",
    "            loss = loss\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def use_wandb() -> bool:\n",
    "    return bool(int(os.environ.get(\"WANDB\", \"0\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path as pt\n",
    "from typing import List\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from fcdd.datasets import load_dataset\n",
    "from fcdd.datasets.bases import GTMapADDataset\n",
    "from fcdd.models import load_nets\n",
    "from fcdd.models.bases import BaseNet\n",
    "from fcdd.util.logging import Logger\n",
    "from fcdd.training.setup import pick_opt_sched\n",
    "import json\n",
    "import os.path as pt\n",
    "import re\n",
    "import time\n",
    "import traceback\n",
    "from collections import defaultdict\n",
    "from copy import deepcopy\n",
    "from argparse import ArgumentParser\n",
    "from fcdd.training.fcdd import FCDDTrainer\n",
    "\n",
    "\n",
    "# the names come from trainer.test()\n",
    "RunResults = namedtuple('RunResults', [\"roc\", \"gtmap_roc\",])\n",
    "\n",
    "\n",
    "def run_one(**kwargs):\n",
    "    \"\"\"\n",
    "    kwargs should contain all parameters of the setup function in training.setup\n",
    "    \"\"\"\n",
    "    logdir = kwargs[\"logdir\"]\n",
    "    \n",
    "    if use_wandb():\n",
    "        import wandb\n",
    "        wandb.init(\n",
    "            name=f\"{logdir.parent.parent.name}.{logdir.parent.name}.{logdir.name}\",\n",
    "            project=\"fcdd-train-mvtec-dev00\", \n",
    "            entity=\"mines-paristech-cmm\",\n",
    "            config=kwargs,\n",
    "        )\n",
    "        \n",
    "    kwargs[\"logdir\"] = str(logdir.absolute())\n",
    "    kwargs[\"datadir\"] = str(Path(kwargs[\"datadir\"]).absolute())\n",
    "    readme = kwargs.pop(\"readme\")\n",
    "    kwargs['config'] = f'{json.dumps(kwargs)}\\n\\n{readme}'\n",
    "\n",
    "    acc_batches = kwargs.pop('acc_batches', 1)\n",
    "    epochs = kwargs.pop('epochs')\n",
    "    load_snapshot = kwargs.pop('load', None)  # pre-trained model, path to model snapshot\n",
    "    test = kwargs.pop(\"test\")\n",
    "    \n",
    "    del kwargs[\"log_start_time_str\"]\n",
    "    del kwargs[\"normal_class_label\"]\n",
    "    \n",
    "    try:\n",
    "        # this was the part\n",
    "        # setup = trainer_setup(**kwargs)\n",
    "        # trainer = SuperTrainer(**setup)\n",
    "        setup: TrainSetup = trainer_setup(**kwargs)\n",
    "        trainer = FCDDTrainer(\n",
    "            net=setup.net,\n",
    "            opt=setup.opt,\n",
    "            sched=setup.sched,\n",
    "            dataset_loaders=setup.dataset_loaders,\n",
    "            logger=setup.logger,\n",
    "            gauss_std=setup.gauss_std,\n",
    "            quantile=setup.quantile,\n",
    "            resdown=setup.resdown,\n",
    "            blur_heatmaps=setup.blur_heatmaps,\n",
    "            device=setup.device,\n",
    "            objective=\"fcdd\",  # hardcoded because this is not relevant anymore\n",
    "        )\n",
    "        \n",
    "        if load_snapshot is None:\n",
    "            epoch_start = 0\n",
    "        \n",
    "        else:\n",
    "            epoch_start = trainer.load(load_snapshot)\n",
    "            \n",
    "    except:\n",
    "        if use_wandb():\n",
    "            import wandb\n",
    "            wandb.finish()\n",
    "        raise\n",
    "\n",
    "    try:\n",
    "        # this was the part\n",
    "        # trainer.train(epochs, load, acc_batches=acc_batches)\n",
    "        # epochs: from kwargs, ok\n",
    "        # load: from kwargs, ok\n",
    "        # acc_batches: from kwargs, ok\n",
    "        trainer.train(\n",
    "            epochs=epochs - epoch_start, \n",
    "            acc_batches=acc_batches,\n",
    "            wandb=wandb if use_wandb() else None, \n",
    "        )\n",
    "\n",
    "        if test and (epochs > 0 or load_snapshot is not None):\n",
    "            ret = trainer.test()  # keys = {roc, gtmap_roc}\n",
    "        else:\n",
    "            ret = trainer.res  # keys = {roc, gtmap_roc}\n",
    "\n",
    "        return RunResults(\n",
    "            roc=ret[\"roc\"],\n",
    "            gtmap_roc=ret[\"gtmap_roc\"],\n",
    "        )\n",
    "        \n",
    "    except:\n",
    "        setup.logger.printlog += traceback.format_exc()\n",
    "        raise  # the re-raise is executed after the 'finally' clause\n",
    "\n",
    "    finally:\n",
    "        # joao: the original code had this comment about logger.print_logs()\n",
    "        # no finally statement, because that breaks debugger\n",
    "        # joao: i'm ignoring it to see what happens\n",
    "        # and it was in the except clause of the BaseRunner.run_one()\n",
    "        setup.logger.log_prints() \n",
    "        \n",
    "        setup.logger.save()\n",
    "        setup.logger.plot()\n",
    "        setup.logger.snapshot(trainer.net, trainer.opt, trainer.sched, epochs)\n",
    "\n",
    "        if use_wandb():\n",
    "            wandb.finish()    \n",
    "            \n",
    "                    \n",
    "def run(**kwargs) -> dict:\n",
    "    \n",
    "    original_logdir = kwargs['logdir']\n",
    "    dataset = kwargs['dataset']\n",
    "    \n",
    "    cls_restrictions = kwargs.pop(\"cls_restrictions\", None)\n",
    "    classes = cls_restrictions or range(no_classes(dataset))\n",
    "\n",
    "    number_it = kwargs.pop('it')\n",
    "    its_restrictions = kwargs.pop(\"its_restrictions\", None)\n",
    "    its = its_restrictions or range(number_it)\n",
    "\n",
    "    results = []\n",
    "    \n",
    "    for c in classes:\n",
    "        cls_logdir = original_logdir / f'normal_{c}'\n",
    "        \n",
    "        kwargs['normal_class'] = c\n",
    "        kwargs['normal_class_label'] = str_labels(dataset)[c]\n",
    "    \n",
    "        for i in its:\n",
    "            it_logdir = cls_logdir / 'it_{}'.format(i)\n",
    "            res = run_one(**{**kwargs, **dict(logdir=it_logdir)})  # overwrite logdir\n",
    "            results.append(dict(class_idx=c, it=i, results=res))\n",
    "\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# launch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.14"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/bertoldo/repos/fcdd/python/dev/wandb/run-20220420_165008-2uxrxwc5</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/mines-paristech-cmm/fcdd-train-mvtec-dev00/runs/2uxrxwc5\" target=\"_blank\">mvtec_fcdd_20220420165008.normal_0.it_0</a></strong> to <a href=\"https://wandb.ai/mines-paristech-cmm/fcdd-train-mvtec-dev00\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bertoldo/miniconda3/envs/fcdd_rc21/lib/python3.9/site-packages/torchvision/transforms/transforms.py:280: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded.\n",
      "Loading dataset from /home/bertoldo/repos/fcdd/python/dev/../../data/datasets/mvtec/admvtec_240x240.pt...\n",
      "Dataset complete.\n",
      "Files already downloaded.\n",
      "Loading dataset from /home/bertoldo/repos/fcdd/python/dev/../../data/datasets/mvtec/admvtec_240x240.pt...\n",
      "Dataset complete.\n",
      "Successfully saved code at /home/bertoldo/repos/fcdd/python/dev/../../data/results/mvtec_fcdd_20220420165008/normal_0/it_0/./src.tar.gz\n",
      "Generating dataset preview...\n",
      "Dataset preview generated.\n",
      "EPOCH 00 NBAT 0007/0131 ERR nan ERR_NORMAL nan ERR_ANOMALOUS nan INFO LR ['1e-03'] ID fcdd.training.fcdd.FCDDTrainer\n",
      "EPOCH 00 NBAT 0023/0131 ERR nan ERR_NORMAL nan ERR_ANOMALOUS nan INFO LR ['1e-03'] ID fcdd.training.fcdd.FCDDTrainer\n",
      "EPOCH 00 NBAT 0031/0131 ERR nan ERR_NORMAL nan ERR_ANOMALOUS nan INFO LR ['1e-03'] ID fcdd.training.fcdd.FCDDTrainer\n",
      "EPOCH 00 NBAT 0039/0131 ERR nan ERR_NORMAL nan ERR_ANOMALOUS nan INFO LR ['1e-03'] ID fcdd.training.fcdd.FCDDTrainer\n",
      "EPOCH 00 NBAT 0047/0131 ERR nan ERR_NORMAL nan ERR_ANOMALOUS nan INFO LR ['1e-03'] ID fcdd.training.fcdd.FCDDTrainer\n",
      "EPOCH 00 NBAT 0055/0131 ERR nan ERR_NORMAL nan ERR_ANOMALOUS nan INFO LR ['1e-03'] ID fcdd.training.fcdd.FCDDTrainer\n",
      "EPOCH 00 NBAT 0071/0131 ERR nan ERR_NORMAL nan ERR_ANOMALOUS nan INFO LR ['1e-03'] ID fcdd.training.fcdd.FCDDTrainer\n",
      "EPOCH 00 NBAT 0087/0131 ERR 1.556605 ERR_NORMAL 0.120565 ERR_ANOMALOUS 2.603784 INFO LR ['1e-03'] ID fcdd.training.fcdd.FCDDTrainer\n",
      "EPOCH 00 NBAT 0103/0131 ERR 1.148557 ERR_NORMAL 0.186315 ERR_ANOMALOUS 1.968418 INFO LR ['1e-03'] ID fcdd.training.fcdd.FCDDTrainer\n",
      "EPOCH 00 NBAT 0111/0131 ERR 1.036635 ERR_NORMAL 0.223015 ERR_ANOMALOUS 1.744610 INFO LR ['1e-03'] ID fcdd.training.fcdd.FCDDTrainer\n",
      "EPOCH 00 NBAT 0119/0131 ERR 0.928613 ERR_NORMAL 0.261190 ERR_ANOMALOUS 1.564460 INFO LR ['1e-03'] ID fcdd.training.fcdd.FCDDTrainer\n",
      "EPOCH 00 NBAT 0127/0131 ERR 0.871006 ERR_NORMAL 0.300201 ERR_ANOMALOUS 1.415756 INFO LR ['1e-03'] ID fcdd.training.fcdd.FCDDTrainer\n",
      "EPOCH 01 NBAT 0007/0131 ERR 0.781027 ERR_NORMAL 0.378611 ERR_ANOMALOUS 1.186980 INFO LR ['1e-03'] ID fcdd.training.fcdd.FCDDTrainer\n",
      "EPOCH 01 NBAT 0015/0131 ERR 0.766998 ERR_NORMAL 0.416488 ERR_ANOMALOUS 1.098671 INFO LR ['1e-03'] ID fcdd.training.fcdd.FCDDTrainer\n",
      "EPOCH 01 NBAT 0023/0131 ERR 0.742033 ERR_NORMAL 0.452858 ERR_ANOMALOUS 1.023810 INFO LR ['1e-03'] ID fcdd.training.fcdd.FCDDTrainer\n",
      "EPOCH 01 NBAT 0031/0131 ERR 0.735842 ERR_NORMAL 0.488039 ERR_ANOMALOUS 0.959201 INFO LR ['1e-03'] ID fcdd.training.fcdd.FCDDTrainer\n",
      "EPOCH 01 NBAT 0039/0131 ERR 0.721218 ERR_NORMAL 0.521359 ERR_ANOMALOUS 0.904067 INFO LR ['1e-03'] ID fcdd.training.fcdd.FCDDTrainer\n",
      "EPOCH 01 NBAT 0055/0131 ERR 0.701772 ERR_NORMAL 0.582480 ERR_ANOMALOUS 0.814872 INFO LR ['1e-03'] ID fcdd.training.fcdd.FCDDTrainer\n",
      "EPOCH 01 NBAT 0063/0131 ERR 0.697707 ERR_NORMAL 0.609767 ERR_ANOMALOUS 0.779357 INFO LR ['1e-03'] ID fcdd.training.fcdd.FCDDTrainer\n",
      "EPOCH 01 NBAT 0071/0131 ERR 0.692897 ERR_NORMAL 0.634813 ERR_ANOMALOUS 0.748718 INFO LR ['1e-03'] ID fcdd.training.fcdd.FCDDTrainer\n",
      "EPOCH 01 NBAT 0079/0131 ERR 0.688507 ERR_NORMAL 0.657575 ERR_ANOMALOUS 0.722383 INFO LR ['1e-03'] ID fcdd.training.fcdd.FCDDTrainer\n",
      "EPOCH 01 NBAT 0087/0131 ERR 0.687777 ERR_NORMAL 0.678026 ERR_ANOMALOUS 0.699599 INFO LR ['1e-03'] ID fcdd.training.fcdd.FCDDTrainer\n",
      "EPOCH 01 NBAT 0103/0131 ERR 0.688346 ERR_NORMAL 0.714126 ERR_ANOMALOUS 0.662259 INFO LR ['1e-03'] ID fcdd.training.fcdd.FCDDTrainer\n",
      "EPOCH 01 NBAT 0111/0131 ERR 0.688383 ERR_NORMAL 0.729257 ERR_ANOMALOUS 0.647558 INFO LR ['1e-03'] ID fcdd.training.fcdd.FCDDTrainer\n",
      "EPOCH 01 NBAT 0119/0131 ERR 0.689226 ERR_NORMAL 0.742733 ERR_ANOMALOUS 0.635121 INFO LR ['1e-03'] ID fcdd.training.fcdd.FCDDTrainer\n",
      "EPOCH 01 NBAT 0127/0131 ERR 0.689238 ERR_NORMAL 0.754214 ERR_ANOMALOUS 0.624449 INFO LR ['1e-03'] ID fcdd.training.fcdd.FCDDTrainer\n",
      "EPOCH 02 NBAT 0007/0131 ERR 0.687512 ERR_NORMAL 0.773842 ERR_ANOMALOUS 0.606378 INFO LR ['1e-03'] ID fcdd.training.fcdd.FCDDTrainer\n",
      "EPOCH 02 NBAT 0015/0131 ERR 0.689224 ERR_NORMAL 0.782251 ERR_ANOMALOUS 0.599585 INFO LR ['1e-03'] ID fcdd.training.fcdd.FCDDTrainer\n",
      "EPOCH 02 NBAT 0023/0131 ERR 0.688857 ERR_NORMAL 0.789323 ERR_ANOMALOUS 0.593636 INFO LR ['1e-03'] ID fcdd.training.fcdd.FCDDTrainer\n",
      "EPOCH 02 NBAT 0031/0131 ERR 0.689808 ERR_NORMAL 0.795512 ERR_ANOMALOUS 0.588341 INFO LR ['1e-03'] ID fcdd.training.fcdd.FCDDTrainer\n",
      "EPOCH 02 NBAT 0039/0131 ERR 0.691316 ERR_NORMAL 0.800312 ERR_ANOMALOUS 0.584413 INFO LR ['1e-03'] ID fcdd.training.fcdd.FCDDTrainer\n",
      "EPOCH 02 NBAT 0055/0131 ERR 0.692538 ERR_NORMAL 0.807680 ERR_ANOMALOUS 0.578330 INFO LR ['1e-03'] ID fcdd.training.fcdd.FCDDTrainer\n",
      "EPOCH 02 NBAT 0063/0131 ERR 0.691909 ERR_NORMAL 0.810030 ERR_ANOMALOUS 0.576311 INFO LR ['1e-03'] ID fcdd.training.fcdd.FCDDTrainer\n",
      "EPOCH 02 NBAT 0071/0131 ERR 0.692496 ERR_NORMAL 0.812058 ERR_ANOMALOUS 0.574489 INFO LR ['1e-03'] ID fcdd.training.fcdd.FCDDTrainer\n",
      "EPOCH 02 NBAT 0079/0131 ERR 0.695412 ERR_NORMAL 0.813107 ERR_ANOMALOUS 0.573521 INFO LR ['1e-03'] ID fcdd.training.fcdd.FCDDTrainer\n",
      "EPOCH 02 NBAT 0095/0131 ERR 0.694788 ERR_NORMAL 0.812562 ERR_ANOMALOUS 0.573392 INFO LR ['1e-03'] ID fcdd.training.fcdd.FCDDTrainer\n",
      "EPOCH 02 NBAT 0103/0131 ERR 0.696545 ERR_NORMAL 0.811397 ERR_ANOMALOUS 0.573958 INFO LR ['1e-03'] ID fcdd.training.fcdd.FCDDTrainer\n",
      "EPOCH 02 NBAT 0111/0131 ERR 0.697138 ERR_NORMAL 0.809755 ERR_ANOMALOUS 0.575548 INFO LR ['1e-03'] ID fcdd.training.fcdd.FCDDTrainer\n",
      "EPOCH 02 NBAT 0119/0131 ERR 0.697319 ERR_NORMAL 0.807591 ERR_ANOMALOUS 0.577148 INFO LR ['1e-03'] ID fcdd.training.fcdd.FCDDTrainer\n",
      "EPOCH 02 NBAT 0127/0131 ERR 0.696236 ERR_NORMAL 0.804921 ERR_ANOMALOUS 0.578937 INFO LR ['1e-03'] ID fcdd.training.fcdd.FCDDTrainer\n",
      "Test training data...\n",
      "TEST 0000/0131 ID fcdd.training.fcdd.FCDDTrainer\n",
      "TEST 0008/0131 ID fcdd.training.fcdd.FCDDTrainer\n",
      "TEST 0016/0131 ID fcdd.training.fcdd.FCDDTrainer\n",
      "TEST 0024/0131 ID fcdd.training.fcdd.FCDDTrainer\n",
      "TEST 0032/0131 ID fcdd.training.fcdd.FCDDTrainer\n",
      "TEST 0041/0131 ID fcdd.training.fcdd.FCDDTrainer\n",
      "TEST 0048/0131 ID fcdd.training.fcdd.FCDDTrainer\n",
      "TEST 0058/0131 ID fcdd.training.fcdd.FCDDTrainer\n",
      "TEST 0065/0131 ID fcdd.training.fcdd.FCDDTrainer\n",
      "TEST 0075/0131 ID fcdd.training.fcdd.FCDDTrainer\n",
      "TEST 0083/0131 ID fcdd.training.fcdd.FCDDTrainer\n",
      "TEST 0092/0131 ID fcdd.training.fcdd.FCDDTrainer\n",
      "TEST 0101/0131 ID fcdd.training.fcdd.FCDDTrainer\n",
      "TEST 0109/0131 ID fcdd.training.fcdd.FCDDTrainer\n",
      "TEST 0118/0131 ID fcdd.training.fcdd.FCDDTrainer\n",
      "TEST 0126/0131 ID fcdd.training.fcdd.FCDDTrainer\n",
      "Test test data...\n",
      "TEST 0000/0006 ID fcdd.training.fcdd.FCDDTrainer\n",
      "Computing test score...\n",
      "##### ROC TEST SCORE 0.5 #####\n",
      "Computing GT test score...\n",
      "Files already downloaded.\n",
      "WARNING: Could not save /home/bertoldo/repos/fcdd/python/dev/../../data/results/mvtec_fcdd_20220420165008/normal_0/it_0/./gtmap_roc.json, because size of dict is 37664216, which exceeded 10MB!\n",
      "##### GTMAP ROC TEST SCORE 0.6358976559775728 #####\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">mvtec_fcdd_20220420165008.normal_0.it_0</strong>: <a href=\"https://wandb.ai/mines-paristech-cmm/fcdd-train-mvtec-dev00/runs/2uxrxwc5\" target=\"_blank\">https://wandb.ai/mines-paristech-cmm/fcdd-train-mvtec-dev00/runs/2uxrxwc5</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20220420_165008-2uxrxwc5/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"3\"\n",
    "os.environ[\"WANDB\"] = \"1\"\n",
    "\n",
    "ARG_STRING = \"--cls-restrictions 0 --it 1 --epochs 3\"\n",
    "\n",
    "args = ARG_STRING.split(\" \")\n",
    "args = parser.parse_args(args=args)\n",
    "args = args_post_parse(args)\n",
    "\n",
    "results = run(**vars(args))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this was in run_seeds\n",
    "# for key in results:\n",
    "#     plot_many_roc(\n",
    "#         logdir.replace('{t}', kwargs[\"log_start_time_str\"], results[key],\n",
    "#         labels=its, mean=True, name=key\n",
    "#     )\n",
    "    \n",
    "# return {key: mean_roc(val) for key, val in results.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this was in run_classes\n",
    "\n",
    "        # this was in the finally of the class loop\n",
    "            # print('Plotting ROC for completed classes up to {}...'.format(c))\n",
    "            # for key in results:\n",
    "            #     plot_many_roc(\n",
    "            #         logdir.replace('{t}', kwargs[\"log_start_time_str\"], results[key],\n",
    "            #         labels=str_labels(kwargs['dataset']), mean=True, name=key\n",
    "            #     )\n",
    "                \n",
    "    # for key in results:\n",
    "    #     plot_many_roc(\n",
    "    #         logdir.replace('{t}', kwargs[\"log_start_time_str\"], results[key],\n",
    "    #         labels=str_labels(kwargs['dataset']), mean=True, name=key\n",
    "    #     )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fcdd_rc21",
   "language": "python",
   "name": "fcdd_rc21"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
