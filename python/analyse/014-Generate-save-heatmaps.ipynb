{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate and save heatmaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a cell print all the outputs instead of just the last one\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Public\\Documents\\DIMA\\fcdd\\python\\analyse\n"
     ]
    }
   ],
   "source": [
    "%cd \"C:\\Users\\Public\\Documents\\DIMA\\fcdd\\python\\analyse\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "FIGS_DIR = Path(\".\") / \"figs\"\n",
    "FIGS_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "DATA_DIR = Path(\".\") / \"data\" # est-ce le bon dossier ?\n",
    "DATA_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "SNAPSHOTS_DIR = Path(\"../../data\")\n",
    "assert SNAPSHOTS_DIR.exists()\n",
    "\n",
    "MVTECAD_DIR= Path(\"../../data/datasets/mvtec\") # est-ce le bon dossier ?\n",
    "assert MVTECAD_DIR.exists()\n",
    "\n",
    "RECORDS_FPATH = DATA_DIR / \"snapshot.pt\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get snapshots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy import ndarray\n",
    "from pathlib import Path\n",
    "import json\n",
    "import re\n",
    "from datetime import timedelta, datetime\n",
    "from typing import Dict, Union, List\n",
    "import copy\n",
    "\n",
    "\n",
    "# this is to get the strings associated to the classes in the fcdd code\n",
    "# copied from: fcdd/python/fcdd/datasets/__init__.py\n",
    "# inside function `str_labels`\n",
    "# commit: 9f268d8fd2fee33a5c5f38cdfb781da927bdb614\n",
    "CLASS_LABELS = {\n",
    "    'cifar10': ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck'],\n",
    "    'fmnist': [\n",
    "        't-shirt/top', 'trouser', 'pullover', 'dress', 'coat', 'sandal', 'shirt', 'sneaker', 'bag', 'ankle boot'\n",
    "    ],\n",
    "    'mvtec': [\n",
    "        'bottle', 'cable', 'capsule', 'carpet', 'grid', 'hazelnut', 'leather',\n",
    "        'metal_nut', 'pill', 'screw', 'tile', 'toothbrush', 'transistor',\n",
    "        'wood', 'zipper'\n",
    "    ],\n",
    "    # 'imagenet': deepcopy(ADImageNet.ad_classes),\n",
    "    # this one forwards to: fcdd/python/fcdd/datasets/imagenet.py\n",
    "    # in: ADImageNet.ad_classes\n",
    "    # at the same commit as above\n",
    "    'imagenet': ['acorn', 'airliner', 'ambulance', 'American alligator', 'banjo', 'barn', 'bikini', 'digital clock',\n",
    "                  'dragonfly', 'dumbbell', 'forklift', 'goblet', 'grand piano', 'hotdog', 'hourglass', 'manhole cover',\n",
    "                  'mosque', 'nail', 'parking meter', 'pillow', 'revolver', 'dial telephone', 'schooner',\n",
    "                  'snowmobile', 'soccer ball', 'stingray', 'strawberry', 'tank', 'toaster', 'volcano'],\n",
    "    'pascalvoc': ['horse'],\n",
    "}\n",
    "\n",
    "def get_classes_labels_order(dataset: str) -> List[str]:\n",
    "    return copy.deepcopy(CLASS_LABELS[dataset])\n",
    "\n",
    "def get_class_label(class_dirname: str, dataset: str) -> str:\n",
    "    return CLASS_LABELS[dataset][int(class_dirname.lstrip(\"normal_\"))]\n",
    "\n",
    "class MissingFileInExperiment(FileNotFoundError):\n",
    "    pass\n",
    "\n",
    "class UnfinishedExperiment(Exception):\n",
    "    pass\n",
    "\n",
    "def get_snapshots(experiment_dir: Path) -> Dict[str, Union[str, float, ndarray]]:\n",
    "    \"\"\"\n",
    "    :param experiment_dir: path to the experiment directory\n",
    "    \"\"\"\n",
    "    snapshots_dir = experiment_dir\n",
    "    \n",
    "    snapshots = []\n",
    "    for snashotpath in snapshots_dir.glob(\"*.pt\"): # modif dans .glob\n",
    "        snapshot_name = snashotpath.name\n",
    "        # epoch = int(snashotpath.stem.split(\"=\")[1]) \n",
    "        snapshots.append({\n",
    "            \"fpath\": snashotpath,\n",
    "            \"snapshot_name\": snapshot_name,\n",
    "            # \"epoch\": epoch,\n",
    "        })\n",
    "        \n",
    "    return snapshots\n",
    "\n",
    "\n",
    "def get_all(path: Path, dataset: str) -> List[Dict[str, Union[str, float, ndarray]]]:\n",
    "    \n",
    "    \"\"\"\n",
    "    :param path: a folder that contains dirs like 'fcdd_20211220193242_fmnist_' \n",
    "                 a whole experiment on a dataset with all iterations and nominal classes inside, \n",
    "                 the structure should look like\n",
    "                 \n",
    "                path/\n",
    "                path/normal_0\n",
    "                path/normal_1\n",
    "                ...\n",
    "                path/normal_9/\n",
    "                path/normal_9/it_0\n",
    "                ...\n",
    "                path/normal_9/it_4/roc.json\n",
    "    \"\"\"\n",
    "    assert path.is_dir()\n",
    "    assert dataset in CLASS_LABELS\n",
    "    \n",
    "    snapshots = []\n",
    "\n",
    "    experiment_snapshots = get_snapshots(path)\n",
    "\n",
    "    for snap in experiment_snapshots:\n",
    "        # print\n",
    "        snapshots.append({\n",
    "            **snap,\n",
    "            **{\n",
    "                \"rootdir\": path,\n",
    "                # \"rundir\": rundir,\n",
    "                # \"classdir\": classdir,\n",
    "                # \"iterdir\": iterdir,\n",
    "                \"rundir_name\": \"snapshot\",\n",
    "                # \"classdir_name\": classdir.name,\n",
    "                \"class_idx\": 1,\n",
    "                \"class_label\": 'carpet',\n",
    "                # \"iterdir_name\": iterdir.name,\n",
    "                \"iter_idx\": 1,\n",
    "                \"epoch\": 1,\n",
    "            },\n",
    "        })\n",
    "\n",
    "    return snapshots\n",
    "\n",
    "\n",
    "# get_all(path=SNAPSHOTS_DIR, dataset=\"mvtec\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading records\n",
      "couldn't find records, recomputing\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'len(records)=1'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import copy\n",
    "import pickle\n",
    "\n",
    "try:\n",
    "    del records\n",
    "    \n",
    "except NameError:\n",
    "    pass\n",
    "\n",
    "try:\n",
    "    print(\"loading records\")\n",
    "    with RECORDS_FPATH.open(\"rw\") as f:\n",
    "        records = pickle.load(f)\n",
    "        \n",
    "except:\n",
    "    \n",
    "    print(\"couldn't find records, recomputing\")\n",
    "    records = get_all(path=SNAPSHOTS_DIR, dataset=\"mvtec\")\n",
    "\n",
    "    # print(\"saving records\")\n",
    "    # with RECORDS_FPATH.open(\"wb\") as f:\n",
    "    #     pickle.dump(records, f)\n",
    "        \n",
    "f\"{len(records)=}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>fpath</th>\n",
       "      <th>snapshot_name</th>\n",
       "      <th>rootdir</th>\n",
       "      <th>class_idx</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rundir_name</th>\n",
       "      <th>class_label</th>\n",
       "      <th>iter_idx</th>\n",
       "      <th>epoch</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>snapshot</th>\n",
       "      <th>carpet</th>\n",
       "      <th>1</th>\n",
       "      <th>1</th>\n",
       "      <td>..\\..\\data\\snapshot.pt</td>\n",
       "      <td>snapshot.pt</td>\n",
       "      <td>..\\..\\data</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                         fpath snapshot_name  \\\n",
       "rundir_name class_label iter_idx epoch                                         \n",
       "snapshot    carpet      1        1      ..\\..\\data\\snapshot.pt   snapshot.pt   \n",
       "\n",
       "                                           rootdir  class_idx  \n",
       "rundir_name class_label iter_idx epoch                         \n",
       "snapshot    carpet      1        1      ..\\..\\data          1  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "index_cols = [\"rundir_name\", \"class_label\", \"iter_idx\", \"epoch\"]\n",
    "# drop_cols = [\"rundir\", \"classdir\", \"iterdir\", \"classdir_name\", \"iterdir_name\"]\n",
    "df_snapshots = pd.DataFrame.from_records(data=records).set_index(index_cols)\n",
    "df_snapshots.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # A travailler\n",
    "\n",
    "# IMAGES_GLOB = \"*.png\"\n",
    "\n",
    "# imgs = []\n",
    "\n",
    "# for classdir in MVTECAD_DIR.glob(\"*\"):\n",
    "    \n",
    "#     if not classdir.is_dir():\n",
    "#         continue    \n",
    "    \n",
    "#     print(f\"{classdir.name=}\")\n",
    "    \n",
    "#     testdir = classdir / \"test\"\n",
    "#     traindir = classdir / \"train\"\n",
    "    \n",
    "#     if not testdir.exists() and not traindir.exists():\n",
    "#         continue\n",
    "    \n",
    "#     print(f\"{testdir.name=}\")    \n",
    "    \n",
    "#     for typedir in testdir.glob(\"*\"):\n",
    "        \n",
    "#         if not typedir.is_dir():\n",
    "#             continue\n",
    "        \n",
    "#         print(f\"{typedir.name=}\")\n",
    "        \n",
    "#         img_paths = list(typedir.glob(IMAGES_GLOB))\n",
    "        \n",
    "#         if len(img_paths) == 0:\n",
    "#             print(\"empty dir\")\n",
    "#             continue  \n",
    "        \n",
    "#         print(f\"{len(img_paths)=}\")      \n",
    "        \n",
    "#         for imgpath in img_paths:\n",
    "#             imgs.append({\n",
    "#                 \"imgpath\": imgpath,\n",
    "#                 \"class\": classdir.name,\n",
    "#                 \"type\": typedir.name,\n",
    "#                 \"set\": \"test\",\n",
    "#                 \"imgidx\": int(imgpath.stem),\n",
    "#             })\n",
    "            \n",
    "#     print(f\"{traindir.name=}\")\n",
    "    \n",
    "#     img_paths = list((traindir / \"good\").glob(IMAGES_GLOB))\n",
    "    \n",
    "#     if len(img_paths) == 0:\n",
    "#         print(\"empty dir\")\n",
    "\n",
    "#     else:\n",
    "#         for imgpath in img_paths:\n",
    "#             imgs.append({\n",
    "#                 \"imgpath\": imgpath,\n",
    "#                 \"class\": classdir.name,\n",
    "#                 \"type\": \"good\",\n",
    "#                 \"set\": \"train\",\n",
    "#                 \"imgidx\": int(imgpath.stem),\n",
    "#             })    \n",
    "    \n",
    "#     print(30 * \"-\")\n",
    "\n",
    "# print(f\"{len(imgs)=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classdir.name='carpet'\n",
      "groundtruthdir.name='ground_truth'\n",
      "typedir.name='color'\n",
      "len(masks_paths)=19\n",
      "typedir.name='cut'\n",
      "len(masks_paths)=17\n",
      "typedir.name='hole'\n",
      "len(masks_paths)=17\n",
      "typedir.name='metal_contamination'\n",
      "len(masks_paths)=17\n",
      "typedir.name='thread'\n",
      "len(masks_paths)=19\n",
      "------------------------------\n",
      "len(masks)=89\n"
     ]
    }
   ],
   "source": [
    "MASKS_GLOB = \"*.png\"\n",
    "\n",
    "masks = []\n",
    "\n",
    "# We only want the \"carpet\" class\n",
    "# If you want all the classes, use a for loop (see notebook 010-generate-predictions-from-snapshots)\n",
    "\n",
    "classdir = MVTECAD_DIR / \"carpet\"\n",
    "\n",
    "print(f\"{classdir.name=}\")\n",
    "\n",
    "groundtruthdir = classdir / \"ground_truth\"\n",
    "\n",
    "print(f\"{groundtruthdir.name=}\")\n",
    "\n",
    "for typedir in groundtruthdir.glob(\"*\"):\n",
    "    \n",
    "    if not typedir.is_dir():\n",
    "        continue\n",
    "    \n",
    "    print(f\"{typedir.name=}\")\n",
    "    \n",
    "    masks_paths = list(typedir.glob(MASKS_GLOB))\n",
    "    \n",
    "    if len(masks_paths) == 0:\n",
    "        print(\"empty dir\")\n",
    "        continue\n",
    "    \n",
    "    print(f\"{len(masks_paths)=}\")\n",
    "    \n",
    "    for maskpath in masks_paths:\n",
    "        masks.append({\n",
    "            \"mask_path\": maskpath.resolve(),\n",
    "            \"class\": classdir.name,\n",
    "            \"type\": typedir.name,\n",
    "            \"set\": \"ground_truth\",\n",
    "            \"mask_idx\": int(maskpath.stem[:3]),\n",
    "        })\n",
    "        \n",
    "\n",
    "print(30 * \"-\")\n",
    "\n",
    "print(f\"{len(masks)=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>mask_path</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>class</th>\n",
       "      <th>type</th>\n",
       "      <th>set</th>\n",
       "      <th>mask_idx</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"11\" valign=\"top\">carpet</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">color</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">ground_truth</th>\n",
       "      <th>0</th>\n",
       "      <td>C:\\Users\\Public\\Documents\\DIMA\\fcdd\\data\\datas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C:\\Users\\Public\\Documents\\DIMA\\fcdd\\data\\datas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C:\\Users\\Public\\Documents\\DIMA\\fcdd\\data\\datas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>C:\\Users\\Public\\Documents\\DIMA\\fcdd\\data\\datas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>C:\\Users\\Public\\Documents\\DIMA\\fcdd\\data\\datas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">thread</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">ground_truth</th>\n",
       "      <th>14</th>\n",
       "      <td>C:\\Users\\Public\\Documents\\DIMA\\fcdd\\data\\datas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>C:\\Users\\Public\\Documents\\DIMA\\fcdd\\data\\datas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>C:\\Users\\Public\\Documents\\DIMA\\fcdd\\data\\datas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>C:\\Users\\Public\\Documents\\DIMA\\fcdd\\data\\datas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>C:\\Users\\Public\\Documents\\DIMA\\fcdd\\data\\datas...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>89 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                             mask_path\n",
       "class  type   set          mask_idx                                                   \n",
       "carpet color  ground_truth 0         C:\\Users\\Public\\Documents\\DIMA\\fcdd\\data\\datas...\n",
       "                           1         C:\\Users\\Public\\Documents\\DIMA\\fcdd\\data\\datas...\n",
       "                           2         C:\\Users\\Public\\Documents\\DIMA\\fcdd\\data\\datas...\n",
       "                           3         C:\\Users\\Public\\Documents\\DIMA\\fcdd\\data\\datas...\n",
       "                           4         C:\\Users\\Public\\Documents\\DIMA\\fcdd\\data\\datas...\n",
       "...                                                                                ...\n",
       "       thread ground_truth 14        C:\\Users\\Public\\Documents\\DIMA\\fcdd\\data\\datas...\n",
       "                           15        C:\\Users\\Public\\Documents\\DIMA\\fcdd\\data\\datas...\n",
       "                           16        C:\\Users\\Public\\Documents\\DIMA\\fcdd\\data\\datas...\n",
       "                           17        C:\\Users\\Public\\Documents\\DIMA\\fcdd\\data\\datas...\n",
       "                           18        C:\\Users\\Public\\Documents\\DIMA\\fcdd\\data\\datas...\n",
       "\n",
       "[89 rows x 1 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df_masks = pd.DataFrame.from_records(data=masks).set_index([\"class\", \"type\", \"set\", \"mask_idx\"])\n",
    "df_masks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get datasets images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # A travailler\n",
    "\n",
    "# IMAGES_GLOB = \"*.png\"\n",
    "\n",
    "# imgs = []\n",
    "\n",
    "# for classdir in MVTECAD_DIR.glob(\"*\"):\n",
    "    \n",
    "#     if not classdir.is_dir():\n",
    "#         continue    \n",
    "    \n",
    "#     print(f\"{classdir.name=}\")\n",
    "    \n",
    "#     testdir = classdir / \"test\"\n",
    "#     traindir = classdir / \"train\"\n",
    "    \n",
    "#     if not testdir.exists() and not traindir.exists():\n",
    "#         continue\n",
    "    \n",
    "#     print(f\"{testdir.name=}\")    \n",
    "    \n",
    "#     for typedir in testdir.glob(\"*\"):\n",
    "        \n",
    "#         if not typedir.is_dir():\n",
    "#             continue\n",
    "        \n",
    "#         print(f\"{typedir.name=}\")\n",
    "        \n",
    "#         img_paths = list(typedir.glob(IMAGES_GLOB))\n",
    "        \n",
    "#         if len(img_paths) == 0:\n",
    "#             print(\"empty dir\")\n",
    "#             continue  \n",
    "        \n",
    "#         print(f\"{len(img_paths)=}\")      \n",
    "        \n",
    "#         for imgpath in img_paths:\n",
    "#             imgs.append({\n",
    "#                 \"imgpath\": imgpath,\n",
    "#                 \"class\": classdir.name,\n",
    "#                 \"type\": typedir.name,\n",
    "#                 \"set\": \"test\",\n",
    "#                 \"imgidx\": int(imgpath.stem),\n",
    "#             })\n",
    "            \n",
    "#     print(f\"{traindir.name=}\")\n",
    "    \n",
    "#     img_paths = list((traindir / \"good\").glob(IMAGES_GLOB))\n",
    "    \n",
    "#     if len(img_paths) == 0:\n",
    "#         print(\"empty dir\")\n",
    "\n",
    "#     else:\n",
    "#         for imgpath in img_paths:\n",
    "#             imgs.append({\n",
    "#                 \"imgpath\": imgpath,\n",
    "#                 \"class\": classdir.name,\n",
    "#                 \"type\": \"good\",\n",
    "#                 \"set\": \"train\",\n",
    "#                 \"imgidx\": int(imgpath.stem),\n",
    "#             })    \n",
    "    \n",
    "#     print(30 * \"-\")\n",
    "\n",
    "# print(f\"{len(imgs)=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classdir.name='carpet'\n",
      "testdir.name='test'\n",
      "typedir.name='color'\n",
      "len(img_paths)=19\n",
      "typedir.name='cut'\n",
      "len(img_paths)=17\n",
      "typedir.name='good'\n",
      "len(img_paths)=28\n",
      "typedir.name='hole'\n",
      "len(img_paths)=17\n",
      "typedir.name='metal_contamination'\n",
      "len(img_paths)=17\n",
      "typedir.name='thread'\n",
      "len(img_paths)=19\n",
      "traindir.name='train'\n",
      "------------------------------\n",
      "len(imgs)=397\n"
     ]
    }
   ],
   "source": [
    "IMAGES_GLOB = \"*.png\"\n",
    "\n",
    "imgs = []\n",
    "\n",
    "# We only want the \"carpet\" class\n",
    "# If you want all the classes, use a for loop (see notebook 010-generate-predictions-from-snapshots)\n",
    "classdir = MVTECAD_DIR / \"carpet\"\n",
    "\n",
    "\n",
    "print(f\"{classdir.name=}\")\n",
    "\n",
    "testdir = classdir / \"test\"\n",
    "traindir = classdir / \"train\"\n",
    "\n",
    "print(f\"{testdir.name=}\")\n",
    "\n",
    "for typedir in testdir.glob(\"*\"):\n",
    "    \n",
    "    if not typedir.is_dir():\n",
    "        continue\n",
    "    \n",
    "    print(f\"{typedir.name=}\")\n",
    "    \n",
    "    img_paths = list(typedir.glob(IMAGES_GLOB))\n",
    "    \n",
    "    if len(img_paths) == 0:\n",
    "        print(\"empty dir\")\n",
    "        continue  \n",
    "    \n",
    "    print(f\"{len(img_paths)=}\")      \n",
    "    \n",
    "    for imgpath in img_paths:\n",
    "        imgs.append({\n",
    "            \"imgpath\": imgpath.resolve(),\n",
    "            \"class\": classdir.name,\n",
    "            \"type\": typedir.name,\n",
    "            \"set\": \"test\",\n",
    "            \"imgidx\": int(imgpath.stem),\n",
    "        })\n",
    "        \n",
    "print(f\"{traindir.name=}\")\n",
    "\n",
    "img_paths = list((traindir / \"good\").glob(IMAGES_GLOB))\n",
    "\n",
    "if len(img_paths) == 0:\n",
    "    print(\"empty dir\")\n",
    "\n",
    "else:\n",
    "    for imgpath in img_paths:\n",
    "        imgs.append({\n",
    "            \"imgpath\": imgpath.resolve(),\n",
    "            \"class\": classdir.name,\n",
    "            \"type\": \"good\",\n",
    "            \"set\": \"train\",\n",
    "            \"imgidx\": int(imgpath.stem),\n",
    "        })    \n",
    "\n",
    "print(30 * \"-\")\n",
    "\n",
    "print(f\"{len(imgs)=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>imgpath</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>class</th>\n",
       "      <th>set</th>\n",
       "      <th>type</th>\n",
       "      <th>imgidx</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"11\" valign=\"top\">carpet</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">test</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">color</th>\n",
       "      <th>0</th>\n",
       "      <td>C:\\Users\\Public\\Documents\\DIMA\\fcdd\\data\\datas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C:\\Users\\Public\\Documents\\DIMA\\fcdd\\data\\datas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C:\\Users\\Public\\Documents\\DIMA\\fcdd\\data\\datas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>C:\\Users\\Public\\Documents\\DIMA\\fcdd\\data\\datas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>C:\\Users\\Public\\Documents\\DIMA\\fcdd\\data\\datas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">train</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">good</th>\n",
       "      <th>275</th>\n",
       "      <td>C:\\Users\\Public\\Documents\\DIMA\\fcdd\\data\\datas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>276</th>\n",
       "      <td>C:\\Users\\Public\\Documents\\DIMA\\fcdd\\data\\datas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>277</th>\n",
       "      <td>C:\\Users\\Public\\Documents\\DIMA\\fcdd\\data\\datas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>278</th>\n",
       "      <td>C:\\Users\\Public\\Documents\\DIMA\\fcdd\\data\\datas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>279</th>\n",
       "      <td>C:\\Users\\Public\\Documents\\DIMA\\fcdd\\data\\datas...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>397 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                     imgpath\n",
       "class  set   type  imgidx                                                   \n",
       "carpet test  color 0       C:\\Users\\Public\\Documents\\DIMA\\fcdd\\data\\datas...\n",
       "                   1       C:\\Users\\Public\\Documents\\DIMA\\fcdd\\data\\datas...\n",
       "                   2       C:\\Users\\Public\\Documents\\DIMA\\fcdd\\data\\datas...\n",
       "                   3       C:\\Users\\Public\\Documents\\DIMA\\fcdd\\data\\datas...\n",
       "                   4       C:\\Users\\Public\\Documents\\DIMA\\fcdd\\data\\datas...\n",
       "...                                                                      ...\n",
       "       train good  275     C:\\Users\\Public\\Documents\\DIMA\\fcdd\\data\\datas...\n",
       "                   276     C:\\Users\\Public\\Documents\\DIMA\\fcdd\\data\\datas...\n",
       "                   277     C:\\Users\\Public\\Documents\\DIMA\\fcdd\\data\\datas...\n",
       "                   278     C:\\Users\\Public\\Documents\\DIMA\\fcdd\\data\\datas...\n",
       "                   279     C:\\Users\\Public\\Documents\\DIMA\\fcdd\\data\\datas...\n",
       "\n",
       "[397 rows x 1 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "imgs = pd.DataFrame.from_records(data=imgs).set_index([\"class\", \"set\", \"type\", \"imgidx\"])\n",
    "imgs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">imgidx</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>min</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>set</th>\n",
       "      <th>type</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">test</th>\n",
       "      <th>color</th>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cut</th>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>good</th>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hole</th>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>metal_contamination</th>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>thread</th>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train</th>\n",
       "      <th>good</th>\n",
       "      <td>0</td>\n",
       "      <td>279</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          imgidx     \n",
       "                             min  max\n",
       "set   type                           \n",
       "test  color                    0   18\n",
       "      cut                      0   16\n",
       "      good                     0   27\n",
       "      hole                     0   16\n",
       "      metal_contamination      0   16\n",
       "      thread                   0   18\n",
       "train good                     0  279"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pandas import DataFrame\n",
    "\n",
    "selected_class = \"carpet\"\n",
    "\n",
    "class_imgs = imgs.loc[selected_class]\n",
    "\n",
    "def get_indices_summary(df_: DataFrame) -> DataFrame:\n",
    "    return df_.reset_index()[df_.index.names].groupby(df_.index.names[0:2]).agg([\"min\", \"max\"])\n",
    "\n",
    "get_indices_summary(class_imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['color', 'cut', 'good', 'hole', 'metal_contamination', 'thread'], dtype='object', name='type')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_imgs.index.get_level_values(1).unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import DataFrame\n",
    "import time\n",
    "from pathlib import Path\n",
    "from typing import List\n",
    "\n",
    "\n",
    "def create_tmpdir(img_fpaths: List[Path], tmp_dpath: Path):\n",
    "\n",
    "    tmp_img_dir = tmp_dpath / tmp_dpath.name\n",
    "    tmp_img_dir.mkdir(parents=True)\n",
    "\n",
    "    for img_idx, img_fpath in enumerate(img_fpaths):\n",
    "        # create a file name with the parents names\n",
    "        symlink_name = f\"{img_idx:05}-{img_fpath.parent.parent.parent.name}-{img_fpath.parent.parent.name}-{img_fpath.parent.name}-{img_fpath.name}\"\n",
    "        symlink_fpath = tmp_img_dir / symlink_name\n",
    "        symlink_fpath.symlink_to(img_fpath)\n",
    "\n",
    "tmp_dpath = DATA_DIR / f\"tmp_{int(time.time())}\"\n",
    "tmp_dpath = tmp_dpath.absolute()\n",
    "\n",
    "create_tmpdir(\n",
    "    img_fpaths = list(class_imgs[\"imgpath\"]),\n",
    "    tmp_dpath = tmp_dpath,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_names = []\n",
    "img_fpaths = list(class_imgs[\"imgpath\"])\n",
    "for img_idx, img_fpath in enumerate(img_fpaths):\n",
    "    # create a file name with the parents names\n",
    "    name = f\"{img_idx:05}-{img_fpath.parent.parent.parent.name}-{img_fpath.parent.parent.name}-{img_fpath.parent.name}-{img_fpath.name}\"\n",
    "    img_names.append(name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate explanations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data.dataloader import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload 2\n",
    "from fcdd.training.fcdd import FCDDTrainer\n",
    "from fcdd.models.fcdd_cnn_224 import FCDD_CNN224_VGG_F\n",
    "from fcdd.datasets.image_folder import ImageFolder\n",
    "from fcdd.datasets.preprocessing import local_contrast_normalization\n",
    "from fcdd.util.logging import Logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_max_l1 = [\n",
    "    [(-1.3336724042892456, -1.3107913732528687, -1.2445921897888184),\n",
    "     (1.3779616355895996, 1.3779616355895996, 1.3779616355895996)],\n",
    "    [(-2.2404820919036865, -2.3387579917907715, -2.2896201610565186),\n",
    "     (4.573435306549072, 4.573435306549072, 4.573435306549072)],\n",
    "    [(-3.184587001800537, -3.164201259613037, -3.1392977237701416),\n",
    "     (1.6995097398757935, 1.6011602878570557, 1.5209171772003174)],\n",
    "    [(-3.0334954261779785, -2.958242416381836, -2.7701096534729004),\n",
    "     (6.503103256225586, 5.875098705291748, 5.814228057861328)],\n",
    "    [(-3.100773334503174, -3.100773334503174, -3.100773334503174),\n",
    "     (4.27892541885376, 4.27892541885376, 4.27892541885376)],\n",
    "    [(-3.6565306186676025, -3.507692813873291, -2.7635035514831543),\n",
    "     (18.966819763183594, 21.64590072631836, 26.408710479736328)],\n",
    "    [(-1.5192601680755615, -2.2068002223968506, -2.3948357105255127),\n",
    "     (11.564697265625, 10.976534843444824, 10.378695487976074)],\n",
    "    [(-1.3207964897155762, -1.2889339923858643, -1.148416519165039),\n",
    "     (6.854909896850586, 6.854909896850586, 6.854909896850586)],\n",
    "    [(-0.9883341193199158, -0.9822461605072021, -0.9288841485977173),\n",
    "     (2.290637969970703, 2.4007883071899414, 2.3044068813323975)],\n",
    "    [(-7.236185073852539, -7.236185073852539, -7.236185073852539),\n",
    "     (3.3777384757995605, 3.3777384757995605, 3.3777384757995605)],\n",
    "    [(-3.2036616802215576, -3.221003532409668, -3.305514335632324),\n",
    "     (7.022546768188477, 6.115569114685059, 6.310940742492676)],\n",
    "    [(-0.8915618658065796, -0.8669204115867615, -0.8002046346664429),\n",
    "     (4.4255571365356445, 4.642300128936768, 4.305730819702148)],\n",
    "    [(-1.9086798429489136, -2.0004451274871826, -1.929288387298584),\n",
    "     (5.463134765625, 5.463134765625, 5.463134765625)],\n",
    "    [(-2.9547364711761475, -3.17536997795105, -3.143850803375244),\n",
    "     (5.305514812469482, 4.535006523132324, 3.3618252277374268)],\n",
    "    [(-1.2906527519226074, -1.2906527519226074, -1.2906527519226074),\n",
    "     (2.515115737915039, 2.515115737915039, 2.515115737915039)]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fcdd.datasets import load_dataset\n",
    "from fcdd.runners.run_mvtec import MvtecConfig\n",
    "from argparse import ArgumentParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = ArgumentParser()\n",
    "parser = MvtecConfig()(parser)\n",
    "dftargs = parser.parse_args(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# todo change me\n",
    "OUTPUTS_DIR = DATA_DIR.absolute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [optional] to generate heatmaps, define a logger (with the path where the heatmaps should be saved to) and a quantile\n",
    "import time\n",
    "exp_start_time = int(time.time())\n",
    "logger = Logger(str(OUTPUTS_DIR), exp_start_time=exp_start_time)\n",
    "quantile = 0.97"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_heatmaps_for_training(list_snaphots_paths, normal_class):\n",
    "    \n",
    "    net = FCDD_CNN224_VGG_F((3, 224, 224), bias=True)\n",
    "    \n",
    "    # Use the same test transform as was used for training the snapshot\n",
    "    # (e.g., for mvtec, per default, the following)\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize(224),\n",
    "        # transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Lambda(lambda x: local_contrast_normalization(x, scale='l1')),\n",
    "        transforms.Normalize(\n",
    "            min_max_l1[normal_class][0],\n",
    "            [ma - mi for ma, mi in zip(min_max_l1[normal_class][1], min_max_l1[normal_class][0])]\n",
    "        )\n",
    "    ])\n",
    "    \n",
    "    all_all_inputs = []\n",
    "    all_all_labels = []\n",
    "    all_all_anomaly_scores_pixelwise = [] \n",
    "    all_all_anomaly_scores_imgwise = [] \n",
    "    \n",
    "    for snapshot_fpath in list_snaphots_paths:\n",
    "\n",
    "        trainer = FCDDTrainer(net, None, None, (None, None), logger, 'fcdd', 8, quantile, 224)\n",
    "        trainer.load(str(snapshot_fpath), cpu=True)\n",
    "        trainer.net.eval()\n",
    "\n",
    "        data_set = ImageFolder(tmp_dpath, transform)\n",
    "        loader = DataLoader(data_set, batch_size=8, num_workers=0)\n",
    "\n",
    "        all_anomaly_scores, all_inputs, all_labels = [], [], []\n",
    "        for inputs, labels in loader:\n",
    "            # inputs = inputs.cuda()\n",
    "            with torch.no_grad():\n",
    "                outputs = trainer.net(inputs)\n",
    "                anomaly_scores = trainer.anomaly_score(trainer.loss(outputs, inputs, labels, reduce='none'))\n",
    "                anomaly_scores = trainer.net.receptive_upsample(anomaly_scores, reception=True, std=8, cpu=False)\n",
    "                all_anomaly_scores.append(anomaly_scores.cpu())\n",
    "                all_inputs.append(inputs.cpu())\n",
    "                all_labels.append(labels)\n",
    "\n",
    "        all_inputs = torch.cat(all_inputs)\n",
    "        all_labels = torch.cat(all_labels)\n",
    "        # all_anomaly_scores will be a tensor containing pixel-wise anomaly scores for all images\n",
    "        anomaly_scores_pixelwise = torch.cat(all_anomaly_scores)\n",
    "        anomaly_scores_imgwise = trainer.reduce_ascore(anomaly_scores_pixelwise)\n",
    "        \n",
    "        all_all_inputs.append(all_inputs)\n",
    "        all_all_labels.append(all_labels)\n",
    "        all_all_anomaly_scores_pixelwise.append(anomaly_scores_pixelwise)\n",
    "        all_all_anomaly_scores_imgwise.append(anomaly_scores_imgwise)\n",
    "    \n",
    "    all_all_inputs = torch.cat([torch.unsqueeze(t, 0) for t in all_all_inputs], dim=0)\n",
    "    all_all_labels = torch.cat([torch.unsqueeze(t, 0) for t in all_all_labels], dim=0)\n",
    "    all_all_anomaly_scores_pixelwise = torch.cat([torch.unsqueeze(t, 0) for t in all_all_anomaly_scores_pixelwise], dim=0)\n",
    "    all_all_anomaly_scores_imgwise = torch.cat([torch.unsqueeze(t, 0) for t in all_all_anomaly_scores_imgwise], dim=0)\n",
    "    \n",
    "    return all_all_inputs, all_all_labels, all_all_anomaly_scores_pixelwise, all_all_anomaly_scores_imgwise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sophi\\AppData\\Local\\Temp\\ipykernel_13752\\235826052.py:10: FutureWarning: In a future version of pandas all arguments of DataFrame.sort_index will be keyword-only.\n",
      "  df_ = df_.sort_index(0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded net_state, opt_state, sched_state with starting epoch 200 for fcdd.training.fcdd.FCDDTrainer\n"
     ]
    }
   ],
   "source": [
    "index0 = df_snapshots.index.get_level_values(0).unique()[0]\n",
    "df_ = df_snapshots.loc[index0]\n",
    "\n",
    "normal_class_label = df_.index.get_level_values(0).unique()[0]\n",
    "df_ = df_.loc[normal_class_label]\n",
    "\n",
    "iter_idx = df_.index.get_level_values(0).unique()[0]\n",
    "df_ = df_.loc[iter_idx]\n",
    "\n",
    "df_ = df_.sort_index(0)\n",
    "\n",
    "list_snaphots_paths = list(df_snapshots[\"fpath\"])\n",
    "\n",
    "inputs, labels, as_pixelwise, as_imgwise = gen_heatmaps_for_training(\n",
    "    list_snaphots_paths=list_snaphots_paths,\n",
    "    normal_class=get_classes_labels_order(\"mvtec\").index(normal_class_label)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 397, 3, 224, 224])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 397, 1, 224, 224])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 397])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs.shape # images\n",
    "as_pixelwise.shape # result pixel-wise (mask)\n",
    "as_imgwise.shape # result image-wise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs2 = torch.squeeze(inputs)\n",
    "as_pixelwise2 = torch.squeeze(as_pixelwise)\n",
    "as_imgwise2 = torch.squeeze(as_imgwise)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save heatmaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "from matplotlib import image\n",
    "\n",
    "# We want to save the heatmaps in as_pixelwise2\n",
    "\n",
    "HEATMAPS_DIR = Path(\".\") / \"data\" / \"generated_heatmaps\" / \"carpet_train_test\"\n",
    "HEATMAPS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "as_pixelwise2_np = as_pixelwise2.numpy()\n",
    "global_heatmaps_min = as_pixelwise2_np.min()\n",
    "global_heatmaps_max = as_pixelwise2_np.max()\n",
    "\n",
    "# # A améliorer: récupérer plutôt le nom du fichier\n",
    "# labels_list = [f\"1-color-{i:03}\" for i in range(19)]\n",
    "# labels_list += [f\"2-cut-{i:03}\" for i in range(17)]\n",
    "# labels_list += [f\"3-good-{i:03}\" for i in range(28)]\n",
    "# labels_list += [f\"4-hole-{i:03}\" for i in range(17)]\n",
    "# labels_list += [f\"5-metal-{i:03}\" for i in range(17)]\n",
    "# labels_list += [f\"6-thread-{i:03}\" for i in range(19)]\n",
    "# labels_list += [f\"7-good-{i:03}\" for i in range(280)]\n",
    "\n",
    "for array, name in zip(as_pixelwise2_np, img_names) :\n",
    "    array = (array - global_heatmaps_min)/(global_heatmaps_max - global_heatmaps_min)\n",
    "    image.imsave(HEATMAPS_DIR/name, array);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "8d8d05ed87e337413656f0bd9178462fe9e2ca49219e8d2a45967f66d508bfb6"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('fcdd_dima2022')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
